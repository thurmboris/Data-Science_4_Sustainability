{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dc4475-7f7d-4457-8762-bb031a0629b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT YOUR LIBRARIES HERE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from math import comb\n",
    "\n",
    "# Sklearn import\n",
    "from sklearn.model_selection import train_test_split # Splitting the data set\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler # Normalization and standard scaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder # Encoders\n",
    "from sklearn.preprocessing import PolynomialFeatures # Polynomial features\n",
    "from sklearn.preprocessing import FunctionTransformer # Transform data\n",
    "from sklearn.linear_model import LinearRegression # Regression linear model\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet  # Regularization\n",
    "from sklearn.linear_model import LassoCV, RidgeCV  # Regularization and Cross-Validation\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV # Logistic regression model\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNN Algorithm\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree # Decision Trees\n",
    "from sklearn.model_selection import GridSearchCV   # Grid search for cross validation\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error # Metrics regression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score  # Metrics classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a844a8c0-078c-4946-8927-e570469c601c",
   "metadata": {},
   "source": [
    "# Assignment \n",
    "\n",
    "Welcome to the assignment! \n",
    "\n",
    "You will have to implement regression and classification algorithms, applying these methods to the topics of agriculture, food, water, and health. More precisely, you will try to:\n",
    "- predict crop yields using data on weather and fertilizer use;\n",
    "- predict the potability of water using data on the physical and chemical properties of water.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Once you are done you have to submit your notebook here: \n",
    "\n",
    "There is no quiz, so your grade will depend only on your notebook.\n",
    "\n",
    "If there is need for further clarifications on the questions, after the assignment is released, we will update this file, so make sure you check the git repository for updates.\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306ac928-a1e5-4dd7-8e62-b8108c22e5a9",
   "metadata": {},
   "source": [
    "## Linear regression: predicting crop yields\n",
    "\n",
    "Agriculture plays a critical role in the global economy. Given the ongoing growth of the world population, it is imperative to comprehend crop yield at a global level in order to tackle food security issues and mitigate the effects of climate change.\n",
    "\n",
    "Crop yield prediction is an important agricultural problem. The Agricultural yield primarily depends on weather conditions (rain, temperature, etc) and fertilizers use. Having precise information regarding the historical crop yield is critical for making informed decisions regarding agricultural risk management and future projections.\n",
    "\n",
    "Some E4S publications on the topic of food:\n",
    "- [Threats to Nitrogen Fertilizer, Opportunities to Cultivate Sustainable Practices?](https://e4s.center/resources/reports/threats-to-nitrogen-fertilizer-opportunities-to-cultivate-sustainable-practices/)\n",
    "- [True cost of food as a lever to transform the Swiss food system](https://e4s.center/resources/reports/true-cost-of-food-as-a-lever-to-transform-the-swiss-food-system/)\n",
    "\n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/b/b7/Sustainable_Development_Goal_02ZeroHunger.svg/800px-Sustainable_Development_Goal_02ZeroHunger.svg.png' width=\"200\">\n",
    "\n",
    "We will use data obtained from the [FAO](http://www.fao.org/home/en/) (Food and Agriculture Organization) and [World Data Bank](https://data.worldbank.org/), and gathered in the [Crop Yield Prediction Dataset](https://www.kaggle.com/datasets/patelris/crop-yield-prediction-dataset).\n",
    "\n",
    "Our goal is to predict the crop yields using the temperature, rain fall, country, and type of crops.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783579c9-3e8e-4b44-b95a-58179f897d40",
   "metadata": {},
   "source": [
    "### Question 1: Load and Discover the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beccfea-24ca-4c3f-92f1-c5a950b2cbce",
   "metadata": {},
   "source": [
    "- Load the data in a dataframe. The url link is provided below. Display the first 10 observations and the types of data **1 point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e87e292-3eed-4193-ba24-60693606b433",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_yield = 'https://raw.githubusercontent.com/michalis0/MGT-502-Data-Science-and-Machine-Learning/main/data/yield_df.csv'\n",
    "\n",
    "# Import data in dataframe\n",
    "food = pd.read_csv(url_yield)\n",
    "# Display first 10 observations\n",
    "display(food.head(10))\n",
    "# Print the data types\n",
    "print(food.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20cd7b0-d2ba-43cd-a8da-72dd3f4160df",
   "metadata": {},
   "source": [
    "We have some numerical variables (pesticides, rainfall, temperature, yield, and year) and some categorical variables (area and item)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0916a03-2452-43da-9c5d-c5f43fddd8f2",
   "metadata": {},
   "source": [
    "- Print the list of countries ('Area') and years available in the dataset **1 point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af13bb43-fe6f-49ec-b2a4-2faee5cee321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of unique countries\n",
    "country_list = food.Area.unique() \n",
    "\n",
    "# Print result\n",
    "## We use join to print our lists element by element, separated by a comma:\n",
    "print('Our dataset contains {} countries: '.format(len(country_list)) + ', '.join(country_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9c18f7-9604-439b-8c26-83157036810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of unique years as strings\n",
    "## We use a list comprehension to convert our years into string:\n",
    "years_str = [str(y) for y in food.Year.unique()]\n",
    "\n",
    "# Print result\n",
    "print('Our dataset contains the following years: '\n",
    "      +', '.join(years_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c92f5c7-b11c-428b-9c7c-93406aa3f413",
   "metadata": {},
   "source": [
    "- Print the list of 'Item' in the dataset. You should obtain a list of 10 crops, which are among the most consumed in the world **1 point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c32aba-b1fa-46c6-b1e6-0582ab9ca55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of unique item\n",
    "item_list = food.Item.unique() \n",
    "\n",
    "# Print result\n",
    "print('Our dataset contains {} types of crops: '.format(len(item_list)) \n",
    "      + ', '.join(item_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0118e44-ca7c-4a81-998f-c8bccf4248e2",
   "metadata": {},
   "source": [
    "- Display summary statistics for the columns: 'hg/ha_yield', 'average_rain_fall_mm_per_year', 'pesticides_tonnes','avg_temp'. How many observations do we have? **1 point**\n",
    "\n",
    "*Hint:* You can extract the columns 'hg/ha_yield', 'average_rain_fall_mm_per_year', 'pesticides_tonnes','avg_temp' in a new dataframe since we will reuse it in the following questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e212211-7d8d-41e7-a20f-9bcaadf9122e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract columns of interest\n",
    "food_data = food.loc[:,['hg/ha_yield', 'average_rain_fall_mm_per_year', 'pesticides_tonnes','avg_temp']]\n",
    "\n",
    "# Summary statistics\n",
    "display(food_data.describe())\n",
    "\n",
    "# Number of observations\n",
    "print('Our dataset contains {} observations.'.format(food.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a995d1b-a04b-4e57-bfd9-26db5a4a0f53",
   "metadata": {},
   "source": [
    "- Display a heatmap of the correlation matrix between the columns: 'hg/ha_yield', 'average_rain_fall_mm_per_year', 'pesticides_tonnes','avg_temp' **1 point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13cf896-70a1-45e6-b19a-7a7d8e9c0ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We rename the columns of our dataframe for clarity\n",
    "food_data.rename(columns = {'hg/ha_yield':'Yield',\n",
    "                           'average_rain_fall_mm_per_year':'Rainfall',\n",
    "                           'pesticides_tonnes':'Pesticides',\n",
    "                           'avg_temp':'Temperature'},\n",
    "                 inplace=True)\n",
    "\n",
    "# Correlation matrix\n",
    "food_corr = food_data.corr()\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.title(\"Correlation matrix\")\n",
    "sns.heatmap(food_corr.round(decimals=3), annot=True, \n",
    "            cmap=\"seismic\", vmin=-1, vmax=1)             # Color, min value -1, max value 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e4d566-d5e5-4179-8807-cf7f2eb48bf9",
   "metadata": {},
   "source": [
    "- Create a boxplot of the columns: 'hg/ha_yield', 'average_rain_fall_mm_per_year', 'pesticides_tonnes','avg_temp' **1 point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f14fddf-5f93-44d3-9d2d-c4a35a3b2871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since our variables have very different range, we do separate boxplots (different y-axis)\n",
    "food_data.plot(\n",
    "    kind='box', \n",
    "    subplots=True, \n",
    "    sharey=False,                                         # False to get different y-axis\n",
    "    figsize=(12, 4),\n",
    "    title = 'Box plots of yield, climate variables, and production factors'\n",
    ")\n",
    "plt.subplots_adjust(wspace=0.5)                           # Increase spacing between subplots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a26e9e8-57bc-4e83-be5d-7a8eecdc52d0",
   "metadata": {},
   "source": [
    "- Create a pairplot of the columns: 'hg/ha_yield', 'average_rain_fall_mm_per_year', 'pesticides_tonnes','avg_temp' **1 point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb5c2b1-8ff3-4bf5-96dc-fc09782cf06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(food_data) \n",
    "plt.suptitle('Pair plot of yield, climate variables, and production factors', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12042071-e431-44ff-bfec-f1e7c3550143",
   "metadata": {},
   "source": [
    "From the pair plot and correlation matrix, we notice that there are not obvious relations between the yields and our numerical features (pesticides, temperature, and rainfall). Our prediction exercise will thus be challenging... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e878bc-9a34-4875-8771-f6521c2f1b66",
   "metadata": {},
   "source": [
    "- Feel free to pursue your exploration to better understand your dataset. Although not graded, this might help you better understanding the problem and answer the following questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9869b1-8182-4c7e-a650-2e1739718784",
   "metadata": {},
   "source": [
    "It seems that we have duplicate rows in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef645ef-3117-490f-91fe-083e2f96cc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "food[food.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e05146b-eb38-4cb4-b62f-4f3fda0343b3",
   "metadata": {},
   "source": [
    "Let's explore a bit more. We'll use interactive features to facilitate our exploration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c298a8c-2f7c-45ac-bffc-0c4a516aaf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def interactive_extract(country = country_list, item = item_list, year = food.Year.unique()):\n",
    "    return(food.loc[(food['Area']==country)& (food['Item']==item) & (food['Year']==year)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2a28bc-af70-44e6-abe6-b132fbca972f",
   "metadata": {},
   "source": [
    "We notice that for some countries we have several observations for the same year and item. However, not all of them are duplicates. For instance, if we select Brazil and any item and year, we notice that the temperature is not the same for all observations. We can assume that the duplicates are not actual errors but potentially refer to different locations. For now, we'll thus proceed by keeping all observations. However, if our goal was to design an actual predictive model, we would need to further explore the original data to better understand why we have various values of average temperature, and act accordingly..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9741f056-f011-469c-9527-d1d016ddce83",
   "metadata": {},
   "source": [
    "### Question 2: Multivariate regression \n",
    "\n",
    "We will try to predict the crop yields (column 'hg/ha_yield') using as features: 'Item', 'average_rain_fall_mm_per_year', 'pesticides_tonnes','avg_temp'\n",
    "\n",
    "- Extract your features and outcome **1 point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f218896-30f9-41d9-95a8-7550ab0fcdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = food[['Item', 'average_rain_fall_mm_per_year', 'pesticides_tonnes','avg_temp']]\n",
    "y = food[['hg/ha_yield']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccaf94d-c35f-46b8-ae64-456446f93bf7",
   "metadata": {},
   "source": [
    "- Split between training and test set **1 point**\n",
    "\n",
    "*Note*: Use as option: `test_size=0.2`, `random_state=42`, `shuffle=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebc8bd9-7d91-4b60-a545-dcc254897368",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9511b15e-2147-48c7-82e0-24bf45bd194e",
   "metadata": {},
   "source": [
    "- Encode the column 'Item' using `LabelEncoder` **1 point**\n",
    "\n",
    "*Note*: After training your encoder, you need to transform the values of both the training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c155159a-d993-4dca-8320-5e2a39725929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the column of interest\n",
    "item = X_train['Item'].values\n",
    "item_test = X_test['Item'].values\n",
    "\n",
    "# Define the encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit the encoder\n",
    "le.fit(item)\n",
    "\n",
    "# Transform the train and the test set\n",
    "X_train = X_train.assign(Item=le.transform(item))\n",
    "X_test = X_test.assign(Item=le.transform(item_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ddecb0-9e6a-437f-b81b-331e58a5287a",
   "metadata": {},
   "source": [
    "Let's check how the Item column was transformed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719fc4d2-9884-41b5-8a68-a8099198d873",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c27197-47b0-4d46-a65b-8226d0accef8",
   "metadata": {},
   "source": [
    "- Rescale your features using `MinMaxScaler` **1 point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b429b73-27ca-4816-9377-02114e939a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform the train and the test set\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62901f2-e2c9-46f9-bffe-0d0f431a0f1d",
   "metadata": {},
   "source": [
    "- Build and train a multivariate linear regression model **1 point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb27386b-b84e-4c51-9445-6d6712178d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train our model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52fa49c-f2a9-4c43-8170-80ef1d6f3326",
   "metadata": {},
   "source": [
    "- What is the $R^2$, mean absolute error, and mean square error on the training set? On the test set? What do you think? **1 point**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e84ac6-9785-4997-a219-529b3ed2cd9c",
   "metadata": {},
   "source": [
    "We first define a function to compute the various metrics, before using it and printing the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57cc2ff-8fb3-4815-a4a5-6b9b617b7320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_metrics(model, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"This function returns the MAE, MSE and R2 of a regression model, on the training and test set\"\"\"\n",
    "    # Predict training and test set values\n",
    "    predict_train = model.predict(X_train)\n",
    "    predict_test = model.predict(X_test)\n",
    "    # Metrics on training set\n",
    "    mae_train = mean_absolute_error(y_train, predict_train)\n",
    "    mse_train = mean_squared_error(y_train, predict_train)\n",
    "    r2_train = r2_score(y_train, predict_train)\n",
    "    # Metrics on test set\n",
    "    mae_test = mean_absolute_error(y_test, predict_test)\n",
    "    mse_test = mean_squared_error(y_test, predict_test)\n",
    "    r2_test = r2_score(y_test, predict_test)\n",
    "    # Return metrics\n",
    "    return mae_train, mse_train, r2_train, mae_test, mse_test, r2_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3879f1e6-e350-4955-83b0-e36ed87306da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call our function\n",
    "metrics_multi = regression_metrics(model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Print result\n",
    "print(f\"MAE test set: {metrics_multi[3]:0.1f}; MAE training set: {metrics_multi[0]:0.1f};\")\n",
    "print(f\"MSE test set: {metrics_multi[4]:0.1f}; MSE training set: {metrics_multi[1]:0.1f};\")\n",
    "print(f\"R\\u00b2 test set: {metrics_multi[5]:0.3f}; R\\u00b2 training set: {metrics_multi[2]:0.3f};\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42fb9b5-0e29-4455-ac4c-61c21f785ccd",
   "metadata": {},
   "source": [
    "Our model leads to poor predictions. We can visualize our true vs predicted values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd2c3e4-58bc-4450-83e5-32593d171d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe with true and predicted values\n",
    "df_test_prediction = pd.DataFrame(y_test.values, columns = ['true'])\n",
    "df_test_prediction['predicted'] = model.predict(X_test)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(4,4))\n",
    "sns.scatterplot(df_test_prediction, x='true', y='predicted')\n",
    "plt.plot([0, 500000], [0, 500000],'k--')\n",
    "plt.title('Predicted vs True yield value, multivariate regression')\n",
    "plt.xlabel('True yield value')\n",
    "plt.ylabel('Predicted yield value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ee7320-d129-4cdc-975c-4c682b4ad351",
   "metadata": {},
   "source": [
    "### Question 3: Polynomial features regression\n",
    "\n",
    "We will try to improve the quality of our prediction using `PolynomialFeatures`.\n",
    "\n",
    "- Write a function that is using as inputs the degree of polynomial features (an integer), the training and test set (for your features and outcome), and return the $R^2$, mean absolute error, and mean square error on the training and on the set of a polynomial feature regression **3 points**\n",
    "\n",
    "*Hint:* You do not need to include in your function the splitting, encoding and scaling since we will reuse the ones set created before (as before). Your function should transform your training and test set to integrate polynomial features, then build and train your model, before calculating the various error metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b641bd8-7adb-4edc-85fd-146374bbf9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_poly(degree, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"This function returns the MAE, MSE, and R2 of a polynomial feature regression, \n",
    "    on the training and test set, using as input the chosen degree, training, and test set\"\"\"\n",
    "    # Initiate model with chosen number of degree\n",
    "    poly = PolynomialFeatures(degree)\n",
    "    # Transform our training and test set\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "    # Build and train model\n",
    "    model_poly = LinearRegression(fit_intercept=False)\n",
    "    model_poly.fit(X_train_poly, y_train)\n",
    "    # Use regression_metrics function to return metrics\n",
    "    metrics_poly = regression_metrics(model_poly, X_train_poly, X_test_poly, y_train, y_test)\n",
    "    return metrics_poly "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4980bb-79c8-4fe9-9e44-b2994edff0ba",
   "metadata": {},
   "source": [
    "Let's check our function with 2 degrees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da25b5f7-ad68-41f3-8c1f-6cb610574815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call our function\n",
    "metrics_poly_2 = model_poly(2, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Print result\n",
    "print(f\"MAE test set: {metrics_poly_2[3]:0.1f}; MAE training set: {metrics_poly_2[0]:0.1f};\")\n",
    "print(f\"MSE test set: {metrics_poly_2[4]:0.1f}; MSE training set: {metrics_poly_2[1]:0.1f};\")\n",
    "print(f\"R\\u00b2 test set: {metrics_poly_2[5]:0.3f}; R\\u00b2 training set: {metrics_poly_2[2]:0.3f};\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d9dab7-aabd-4198-8306-f434f5f949e3",
   "metadata": {},
   "source": [
    "- What are the the $R^2$, mean absolute error, and mean square error on the training and on the set of a polynomial features regression with degree = 3? With degree = 7? **1 point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e055746-5a5c-4381-b662-ed548e2cf503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call our function\n",
    "metrics_poly_3 = model_poly(3, X_train, X_test, y_train, y_test)   # Polynomial features with 3 degrees\n",
    "\n",
    "# Print result\n",
    "print(\"Performance metrics for polynomial features with degree 3:\")\n",
    "print(f\"MAE test set: {metrics_poly_3[3]:0.1f}; MAE training set: {metrics_poly_3[0]:0.1f}\")\n",
    "print(f\"MSE test set: {metrics_poly_3[4]:0.1f}; MSE training set: {metrics_poly_3[1]:0.1f}\")\n",
    "print(f\"R\\u00b2 test set: {metrics_poly_3[5]:0.3f}; R\\u00b2 training set: {metrics_poly_3[2]:0.3f}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6233d336-5b13-4dc6-8f79-2146eabb1964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call our function\n",
    "metrics_poly_5 = model_poly(5, X_train, X_test, y_train, y_test)   # Polynomial features with 5 degrees\n",
    "\n",
    "# Print result\n",
    "print(\"Performance metrics for polynomial features with degree 5:\")\n",
    "print(f\"MAE test set: {metrics_poly_5[3]:0.1f}; MAE training set: {metrics_poly_5[0]:0.1f}\")\n",
    "print(f\"MSE test set: {metrics_poly_5[4]:0.1f}; MSE training set: {metrics_poly_5[1]:0.1f}\")\n",
    "print(f\"R\\u00b2 test set: {metrics_poly_5[5]:0.3f}; R\\u00b2 training set: {metrics_poly_5[2]:0.3f}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04100b38-57e6-46c9-9a63-43c141d4b299",
   "metadata": {},
   "source": [
    "- Plot the evolution of the MSE on the training set for a polynomial feature regression model when the degree goes from 2 to 10. On the same figure, plot the MSE on the test set for a polynomial feature regression model, when the degree goes from 2 to 10. Which degree would you choose and why? **2 points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752710bf-a720-41d9-92c7-d196922ad96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = range(2,11)\n",
    "mse_poly_train = []\n",
    "mse_poly_test = []\n",
    "\n",
    "# We loop through our number of degrees, using our model_poly function, and storing the results in lists\n",
    "for d in degree:\n",
    "    metrics_poly = model_poly(d, X_train, X_test, y_train, y_test)\n",
    "    mse_poly_train.append(metrics_poly[1])\n",
    "    mse_poly_test.append(metrics_poly[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea254bc-44d2-4600-b78e-403a20282449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure()\n",
    "plt.plot(degree, mse_poly_train, label = 'Training performance')\n",
    "plt.plot(degree, mse_poly_test, 'k--', label = 'Test performance')\n",
    "plt.title('Evolution of MSE in function of polynomial degree', y=1.05)\n",
    "plt.grid(visible = True)\n",
    "plt.legend()\n",
    "plt.xlabel('Polynomial feature degree')\n",
    "plt.ylabel('Mean Square Errors')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdc1303-fd43-4837-a604-9f508884169e",
   "metadata": {},
   "source": [
    "When we increase the number of degrees, the MSE on both training and test set is decreasing until degree 9. For a degree of 10, the MSE increases, indicating that we probably have overfitting issues. The gain in performance also \"stagnates\" for a degree of 6. \n",
    "\n",
    "To decided on the number of degrees, we should consider the complexity of our model. We have 4 original features: Item, Rainfall, Pesticides, and Temperature. For a polynomial features of degree d, we create $ {4+d}\\choose {d}$$ = \\frac{(4+d)!}{4! d!}$ features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bb1040-bcfe-4b53-950d-f48ca1133719",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_poly_features = pd.DataFrame(index=['Number of polynomial features'])\n",
    "\n",
    "for d in degree:\n",
    "    n_poly_features[str(d)] = [comb(4+d,d)]\n",
    "    \n",
    "n_poly_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bcb95c-7e88-4e45-9a05-4c7b5973528e",
   "metadata": {},
   "source": [
    "Given the tradeoff performance-complexity, we will use 6 degrees in the following. Let's print all regression metrics for polynomial features of degree 6. Instead of directly using our function, we also create a training and test set, to be reused in future questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e738508-5aea-495b-b4ad-8439105cd4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate model with 6 degrees\n",
    "poly = PolynomialFeatures(6)\n",
    "# Transform our training and test set\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "# Build and train model\n",
    "model_poly = LinearRegression(fit_intercept=False)\n",
    "model_poly.fit(X_train_poly, y_train)\n",
    "# Use regression_metrics function to return metrics\n",
    "metrics_poly_6 = regression_metrics(model_poly, X_train_poly, X_test_poly, y_train, y_test)\n",
    "\n",
    "# Print result\n",
    "print(\"Performance metrics for polynomial features with degree 6:\")\n",
    "print(f\"MAE test set: {metrics_poly_6[3]:0.1f}; MAE training set: {metrics_poly_6[0]:0.1f}\")\n",
    "print(f\"MSE test set: {metrics_poly_6[4]:0.1f}; MSE training set: {metrics_poly_6[1]:0.1f}\")\n",
    "print(f\"R\\u00b2 test set: {metrics_poly_6[5]:0.3f}; R\\u00b2 training set: {metrics_poly_6[2]:0.3f}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5443919d-7150-49c6-8efe-6421b6ff65f5",
   "metadata": {},
   "source": [
    "### Question 4: Ridge and cross-validation\n",
    "\n",
    "- Build, train, and evaluate a polynomial features regression model, with Ridge regularization, and cross validation. For number of degree, select the one that you picked before. How does your new model compares to your previous one? **3 points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2ff6d1-f084-4a14-908d-bc3ac129cd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the model\n",
    "model_ridge_cv = RidgeCV(cv=9, fit_intercept=False)\n",
    "\n",
    "# Use fit\n",
    "model_ridge_cv.fit(X_train_poly, y_train)\n",
    "\n",
    "# Use regression_metrics function to return metrics\n",
    "metrics_ridgecv = regression_metrics(model_ridge_cv, X_train_poly, X_test_poly, y_train, y_test)\n",
    "\n",
    "# Results in a dataframe\n",
    "model_performance = pd.DataFrame(index=['MAE','MSE','R2'])\n",
    "model_performance['Polynomial features degree 6']=[metrics_poly_6[3], metrics_poly_6[4], metrics_poly_6[5]]\n",
    "model_performance['Ridge CV degree 6']=[metrics_ridgecv[3], metrics_ridgecv[4], metrics_ridgecv[5]]\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a27cb7-c73f-464a-a3de-afe69c2aab55",
   "metadata": {},
   "source": [
    "The performance of our model decreases. We did not have overfitting issues before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9726e7f3-6c1d-4091-96d6-62cf5ada771e",
   "metadata": {},
   "source": [
    "### Question 5: One-Hot encoding\n",
    "\n",
    "We will check how the encoding influenced our results.\n",
    "\n",
    "- Split your original dataset between training and test set (using the same parameters as in Question 2). This time, encode the column 'Item' using `OneHotEncoder`. Finally, rescale your features. **1 point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fc3a22-a1fa-4c03-a505-fbb3b4413afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split between training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Extract the Item column\n",
    "item = X_train[['Item']]\n",
    "item_test = X_test[['Item']]\n",
    "\n",
    "# Define the encoder\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "# Fit the encoder\n",
    "ohe.fit(item)\n",
    "\n",
    "# Add encoded data to Dataframe\n",
    "X_train[ohe.categories_[0]]=ohe.transform(item).toarray()\n",
    "X_test[ohe.categories_[0]]=ohe.transform(item_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1947479-b0df-45b9-9d93-cc81319b9274",
   "metadata": {},
   "source": [
    "Let's check the results, and verify that the encoding worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8131e3-f4f6-4be4-8c24-aac1cc22f4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X_train.head(5))\n",
    "X_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ae53aa-6afa-40d7-b84e-08f6aae02184",
   "metadata": {},
   "source": [
    "Our encoded data matches with our items (at least for the first five observations...). Let's drop the item column and rescale our features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabaa24b-0691-480c-a288-7aea20522e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop item column\n",
    "X_train = X_train.drop('Item', axis=1)\n",
    "X_test = X_test.drop('Item', axis=1)\n",
    "\n",
    "# Rescale\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562ea67b-63b7-4e3e-81b2-514f592c277e",
   "metadata": {},
   "source": [
    "- Build, train, and evaluate a polynomial features regression model, with the same number of degrees as before, but this time with the one-hot encoded data. How does your model compares to the polynomial features regression model (Question 3)? **2 points**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8833c03e-0864-4cc0-b29f-e0fb592b1111",
   "metadata": {},
   "source": [
    "We need to be careful. Since we did one-hot encoding instead of label encoding, we increased the number of features from 4 to 13. By doing a polynomial feature transformation, we can thus very quickly reach a very high number of features and run into memory issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609b50a1-589c-471f-80eb-268914b2548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_poly_features_ohe = pd.DataFrame(index=['Number of polynomial features'])\n",
    "\n",
    "for d in degree:\n",
    "    n_poly_features_ohe[str(d)] = [comb(13+d,d)]\n",
    "    \n",
    "n_poly_features_ohe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e846948-fc34-44fc-a1b7-5ac9576bd25e",
   "metadata": {},
   "source": [
    "Therefore, instead of a degree 6, we will use a degree 3: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f19c783-76c6-4a18-9282-10cc40fb1d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate model with 3 degrees\n",
    "poly = PolynomialFeatures(3)\n",
    "# Transform our training and test set\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "# Build and train model\n",
    "model_poly_ohe = LinearRegression(fit_intercept=False)\n",
    "model_poly_ohe.fit(X_train_poly, y_train)\n",
    "# Use regression_metrics function to return metrics\n",
    "metrics_poly_ohe_3 = regression_metrics(model_poly_ohe, X_train_poly, X_test_poly, y_train, y_test)\n",
    "\n",
    "# Result in dataframe\n",
    "model_performance['Polynomial features degree 3, label encoder']=[metrics_poly_3[3], metrics_poly_3[4], metrics_poly_3[5]]\n",
    "model_performance['Polynomial features degree 3, one-hot encoder']=[metrics_poly_ohe_3[3], metrics_poly_ohe_3[4], metrics_poly_ohe_3[5]]\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba09f3f0-8672-421a-9c79-e0534b5cc513",
   "metadata": {},
   "source": [
    "One-hot encoding performs better. That being said, it is not surprising since it also is the model with the highest number of parameters (560) compared to the other ones. As a comparison, with label encoding, we could use a degree 8 and still have less parameters, while having lower MSE and MAE.\n",
    "\n",
    "*Note:* You should not use $R^2$ to compare models with different number of features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaa15f4-0324-4d2b-8e7e-433eb3c2f277",
   "metadata": {},
   "source": [
    "Let's visualize our predicted vs true values for the polynomial feature model with one-hot encoding..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d445f03-041e-44e3-a716-e6ac1e085a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe with true and predicted values\n",
    "df_test_prediction['predicted ohe'] = model_poly_ohe.predict(X_test_poly)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(4,4))\n",
    "sns.scatterplot(df_test_prediction, x='true', y='predicted ohe')\n",
    "plt.plot([0, 500000], [0, 500000],'k--')\n",
    "plt.title('Predicted vs True yield value, Polynomial features degree 3 with one-hot encoding')\n",
    "plt.xlabel('True yield value')\n",
    "plt.ylabel('Predicted yield value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867c756b-bff5-435f-b886-fe5ea8cf80d4",
   "metadata": {},
   "source": [
    "It looks not too bad, even though we are still struggling with very high yield values..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da10fe5e-c64b-446a-ad56-f82826468cfa",
   "metadata": {},
   "source": [
    "### Additional exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370e3e5f-ed5b-4573-b051-24846e4cb174",
   "metadata": {},
   "source": [
    "#### Comparing scaling techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06b3a8a-c0ee-4ba9-9605-3ee585f11f6f",
   "metadata": {},
   "source": [
    "Here is a function that returns the performance of different scalers, encoders, and polynomial feature degrees. In addition of the MAE, MSE, and $R^2$, we also return another metrics, namely the [Mean Absolute Percentage Error (MAPE)](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_percentage_error.html) - we'll use this metrics in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020053f1-c1f7-4a8e-9660-28ff80b805a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_algos(degree, scaler, encoder, X, y):\n",
    "    \"\"\"This function returns the MAE, MSE, R2 and MAPE on the training and test set using as input:\n",
    "           - the polynomial feature degree\n",
    "           - the chosen scaler\n",
    "           - the chosen encoder\n",
    "           - the features set X\n",
    "           - the outcome y\"\"\"\n",
    "    \n",
    "    # Splitting dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "    \n",
    "    # Encoding\n",
    "    enc = encoder\n",
    "    item = X_train[['Item']]\n",
    "    item_test = X_test[['Item']]\n",
    "    if str(enc) == 'LabelEncoder()':\n",
    "        enc.fit(item.values.flatten())\n",
    "        X_train = X_train.assign(Item=enc.transform(item.values.flatten()))\n",
    "        X_test = X_test.assign(Item=enc.transform(item_test.values.flatten()))\n",
    "    else:\n",
    "        enc.fit(item)\n",
    "        X_train[enc.categories_[0]]=enc.transform(item).toarray()\n",
    "        X_test[enc.categories_[0]]=enc.transform(item_test).toarray()\n",
    "        X_train = X_train.drop('Item', axis=1)\n",
    "        X_test = X_test.drop('Item', axis=1)\n",
    "        \n",
    "    # Scaling\n",
    "    scal = scaler\n",
    "    X_train = scal.fit_transform(X_train)\n",
    "    X_test = scal.transform(X_test)\n",
    "    \n",
    "    # Polynomial features\n",
    "    poly = PolynomialFeatures(degree)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "\n",
    "    # Build and train model\n",
    "    model = LinearRegression(fit_intercept=False)\n",
    "    model.fit(X_train_poly, y_train)\n",
    "    \n",
    "    # Metrics\n",
    "    metrics = regression_metrics(model, X_train_poly, X_test_poly, y_train, y_test)\n",
    "    mape_train = mean_absolute_percentage_error(y_train, model.predict(X_train_poly))\n",
    "    mape_test = mean_absolute_percentage_error(y_test, model.predict(X_test_poly))\n",
    "    \n",
    "    # Format output\n",
    "    metrics_df = pd.DataFrame([[metrics[0],metrics[3]],\n",
    "                               [metrics[1],metrics[4]],\n",
    "                               [metrics[2],metrics[5]],\n",
    "                               [mape_train, mape_test]], \n",
    "                                index = ['MAE','MSE','R2', 'MAPE'], \n",
    "                                columns = ['Training', 'Test'])\n",
    "    \n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725aa7fe-d082-4253-875e-eca5c3de57e8",
   "metadata": {},
   "source": [
    "We can test our function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1e7bd7-4ad9-4161-9ed9-3765067ed3a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ML_algos(3, StandardScaler(), LabelEncoder(), X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6126077-dd0a-42da-8392-4e96aea55707",
   "metadata": {},
   "source": [
    "Let's compare the performance of different models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b48e364-f3e4-4368-acae-12d10cb6e588",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance = pd.DataFrame()\n",
    "\n",
    "degrees = range(1,4)\n",
    "scalers = [MinMaxScaler(), StandardScaler(), RobustScaler()]\n",
    "encoders = [LabelEncoder(), OneHotEncoder()]\n",
    "\n",
    "for d in degrees:\n",
    "    for e in encoders:\n",
    "        for s in scalers:\n",
    "            test_perf = ML_algos(d, s, e, X, y)[['Test']]\n",
    "            model_performance[f'Model: Degree = {d}, {s}, {e}']=test_perf\n",
    "            \n",
    "model_performance.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b10ed46-4ea4-4995-8f2d-c405dfd3cb57",
   "metadata": {},
   "source": [
    "The model performance is not much influenced by the scaling techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf24a97-323e-4c01-9163-58add15341e9",
   "metadata": {},
   "source": [
    "#### Log-transform yields and pesticides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0defc1-2286-42e8-ac08-a58e1332cf9e",
   "metadata": {},
   "source": [
    "We have seen in our EDA that the yields and pesticides were highly skewed. Let's redo our analysis, but this time we'll first log-transform the yield and pesticide columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ff2926-b4b1-45f5-aa5f-3cc6628112f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and outcome\n",
    "X_log = X.copy()\n",
    "y_log = y.copy()\n",
    "\n",
    "# Log-transform\n",
    "X_log.loc[:,'pesticides_tonnes'] = np.log(X_log['pesticides_tonnes'])\n",
    "y_log.loc[:,'hg/ha_yield'] = np.log(y_log['hg/ha_yield'])\n",
    "\n",
    "display(X_log.head(5))\n",
    "y_log.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8c5baa-2a14-478a-b1d7-610a4f6d52fe",
   "metadata": {},
   "source": [
    "Let's compare the performance of various models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b725bb62-9ce5-4e95-8921-ffa269c865e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log_performance = pd.DataFrame()\n",
    "\n",
    "degrees = range(1,4)\n",
    "encoders = [LabelEncoder(), OneHotEncoder()]\n",
    "\n",
    "for d in degrees:\n",
    "    for e in encoders:\n",
    "        test_perf = ML_algos(d, MinMaxScaler(), e, X, y)[['Test']]\n",
    "        model_log_performance[f'Original Model: Degree = {d}, MinMaxScaler(), {e}']=test_perf       \n",
    "        test_perf_log = ML_algos(d, MinMaxScaler(), e, X_log, y_log)[['Test']]\n",
    "        model_log_performance[f'Log Model: Degree = {d}, MinMaxScaler(), {e}']=test_perf_log\n",
    "            \n",
    "model_log_performance.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de49dad-4924-44e0-9f25-9e0f6e95466a",
   "metadata": {},
   "source": [
    "Bingo, the performance does increase! Note that we cannot rely on MSE and MAE to compare the performance of our models with and without log-transformation of our outcome since these metrics depend on the scale of the outcome variable. On the other hand, [MAPE](https://scikit-learn.org/stable/modules/model_evaluation.html#mean-absolute-percentage-error) is scaled by the maximum true value, hence allowing more meaningful comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08235a6-27ec-45b7-9adc-0eea440b6b02",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "Access to safe drinking-water is essential to health, a basic human right and a component of effective policy for health protection. However, for a least 3 billion people, the quality of the water they depend on is unknown due to a lack of monitoring (see [SDG Goal 6](https://sdgs.un.org/goals/goal6) \"Ensure availability and sustainable management of water and sanitation for all\"). \n",
    "\n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/8/87/Sustainable_Development_Goal_6.png/800px-Sustainable_Development_Goal_6.png' width=\"200\">\n",
    "\n",
    "We will use data from the [Water Quality](https://www.kaggle.com/datasets/mssmartypants/water-quality) dataset to try to predict whether the water is safe to drink depending on the concentration of various minerals and microorganisms. Check the webpage to read a description of the features and get a better understanding of our problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15fbefb-e6b7-47ad-aaf0-d411c82a84f4",
   "metadata": {},
   "source": [
    "### Question 6: Load and Discover the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e484596-0a73-4b6a-a5c5-8a8cd02f8ac2",
   "metadata": {},
   "source": [
    "- Load the data in a dataframe. The url link is provided below. Display the first 10 observations and the types of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b92e6a4-30b0-44b4-b986-9b5d1c472842",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_water = 'https://raw.githubusercontent.com/michalis0/MGT-502-Data-Science-and-Machine-Learning/main/data/waterQuality1.csv'\n",
    "\n",
    "water = pd.read_csv(url_water)\n",
    "display(water.head(10))\n",
    "water.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c68ed6-2ecc-4c1a-9dad-f089e34e532d",
   "metadata": {},
   "source": [
    "- Display summary statistics of your dataset and a heatmap of your correlation matrix **1 point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1128ae7-344f-4b76-ac8c-064fa1ffb293",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None) # Display all columns\n",
    "display(water.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f05aab-e753-4497-af35-729e4fe8242d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "water_corr = water.corr()\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(13, 8))\n",
    "plt.title(\"Correlation matrix\")\n",
    "sns.heatmap(water_corr.round(decimals=2), annot=True, \n",
    "            cmap=\"seismic\", vmin=-1, vmax=1)             # Color, min value -1, max value 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f1fb5b-db18-42f5-ac79-62e80034cd77",
   "metadata": {},
   "source": [
    "- Create a pairplot including the columns \"arsenic\", \"cadmium\", \"chromium\", \"copper\", \"bacteria\", \"viruses\", \"lead\", \"nitrates\", \"mercury\"; and color by the class \"is_safe\" **1 points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8185272-0722-4ae7-921e-8e6f139a0f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_col = ['arsenic', 'cadmium', 'chromium', 'copper', 'bacteria', 'viruses', 'lead', 'nitrates', 'mercury', 'is_safe']\n",
    "water_data = water.loc[:,water_col]\n",
    "\n",
    "sns.pairplot(water_data, \n",
    "             hue ='is_safe',\n",
    "             palette = 'deep') \n",
    "plt.suptitle('Pair plot of water features colored by potability', y=1.02, fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd6215a-f563-4b25-a05d-2d45e544bf17",
   "metadata": {},
   "source": [
    "- Feel free to pursue your exploration to better understand your dataset. Although not graded, this might help you better understanding the problem and answer the following questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e90688-8364-494d-8101-921f37cc4f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3071c9e-1801-4e27-9a4c-8893ac08ef03",
   "metadata": {},
   "source": [
    "### Question 7: Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6522cf94-1f4f-497e-9015-d60f143a47e4",
   "metadata": {},
   "source": [
    "We will try to predict the class \"is_safe\", using all the other features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb034311-33cd-4b05-8f4b-e830ea868bac",
   "metadata": {},
   "source": [
    "- Extract your features and outcome. How many observations do we have of class 0 and of class 1? **1 point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1eef72-a1a4-4dd0-b7fb-b51ed4973fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and outcome\n",
    "X = water.drop(columns='is_safe')\n",
    "y = water['is_safe']\n",
    "\n",
    "# Count observations of class 0 and 1\n",
    "obs_0 = y.value_counts()[0]\n",
    "obs_1 = y.value_counts()[1]\n",
    "print(f'Our dataset contains {obs_0} observations of class 0 and {obs_1} observations of class 1.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39e9c21-ba17-4627-b467-22a14b4cd7fb",
   "metadata": {},
   "source": [
    "- Split between training and test set **1 point**\n",
    "\n",
    "*Note*: Use as parameters for splitting: `test_size=0.2`, `random_state=39`, `shuffle=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5898455-ac15-4eb2-9d48-6c058f191131",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data set into a train and a test data sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=39, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea3208e-e021-4e0e-90f8-f6c6eb81c02a",
   "metadata": {},
   "source": [
    "- Rescale your features using `StandardScaler` **1 point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1b4cb5-1656-4353-8639-5a8a378f5cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform the train and the test set\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a78d5a-7e57-49a3-8f15-7fa6f15e5027",
   "metadata": {},
   "source": [
    "### Question 8: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe653332-9ff8-4ad6-a5ab-4e438a7d4f14",
   "metadata": {},
   "source": [
    "- Build and train a logistic regression classifier, using as parameters `penalty='l2'`, `solver='lbfgs'`, `max_iter=1000` **1 point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cadc026-ffb9-4aea-b541-674127da7e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up our model\n",
    "model_logi = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=1000)\n",
    "\n",
    "# Fit our model\n",
    "model_logi.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cb3a09-4c5e-4e89-84fe-aedfe7df7fc1",
   "metadata": {},
   "source": [
    "- Compute the accuracy on the training and test set. Compare it to the default rate. **1 point** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a716618f-ed45-49d1-8f86-fb000e7304ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy on the training set\n",
    "acc_logi_train = model_logi.score(X_train, y_train)\n",
    "print('Accuracy of Logistic regression classifier on training set: {:.4f}'\n",
    "     .format(acc_logi_train))\n",
    "\n",
    "# Accuracy on test set\n",
    "acc_logi_test = model_logi.score(X_test, y_test)\n",
    "print('Accuracy of Logistic regression classifier on test set: {:.4f}'\n",
    "     .format(acc_logi_test))\n",
    "\n",
    "# Default rate\n",
    "defaultrate = max(obs_0, obs_1)/(water[\"is_safe\"].shape[0])\n",
    "print(f'Default rate = {defaultrate:0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb7effa-5f4c-4559-90dc-51a89c3fe18a",
   "metadata": {},
   "source": [
    "We have unbalanced classes, class 0 representing 88.6% of observations, and thus the default rate is very high. Still, our accuracy is larger than the default rate. In addition, it seems that we do not have overfitting issues since the accuracy on the test set is similar (actually slightly larger) than the training set one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70c2ae2-4659-4ae0-a79a-504b3c76443f",
   "metadata": {},
   "source": [
    "- Plot a heatmap of the confusion matrix. Class 1 is the positive class. How many false positive did we obtain? **1 point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eac357c-07e3-416e-8a25-e36991a65a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "y_pred_logi = model_logi.predict(X_test)\n",
    "\n",
    "# Confusion matrix\n",
    "plt.figure(figsize=(3, 2.5))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_logi), annot=True, cmap='Blues', fmt='.4g')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c306054a-3bb6-435a-9fc0-f73dc116b469",
   "metadata": {},
   "source": [
    "We obtain 21 false positive (predicted class 1 while true label is 0). These values are problematic since we do not want to predict that the water is \"safe\" when it is not..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8755d13-e60d-47a0-8f1b-da6533c7d09a",
   "metadata": {},
   "source": [
    "- What is the precision, recall, and f1 score of class 1? Interpret the result. **1 point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f534e8c8-e260-44a5-a919-87a2b5766ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_logi = precision_score(y_test, y_pred_logi)   # Precision\n",
    "recall_logi = recall_score(y_test, y_pred_logi)         # Recall\n",
    "f1_logi = f1_score(y_test, y_pred_logi)                 # f1-score\n",
    "\n",
    "print(f'The precision for class 1 (safe water) is: {precision_logi:0.3f}')\n",
    "print(f'The recall for class 1 is: {recall_logi:0.3f}')\n",
    "print(f'The F1 score for class 1 is: {f1_logi:0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03372d90-8f18-4488-9116-92da8fdb3ec0",
   "metadata": {},
   "source": [
    "We already observed from the confusion matrix that our model was not performing well at predicting class 1, i.e., we have a low recall. On the other hand, the precision is larger. It is good news since our objective is to predict when the water is safe, i.e., we favor higher precision and lower recall. Still, our model needs improvements..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0dd998-c956-4728-9075-34cb13eeee1e",
   "metadata": {},
   "source": [
    "- Build and train a logistic regression classifier with cross-validation, using 5 folds **1 point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f345bab1-5985-401f-8141-f01198cb1028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up our model\n",
    "model_logi_cv = LogisticRegressionCV(penalty='l2', solver='lbfgs', cv=5, max_iter=1000)\n",
    "\n",
    "# Fit our model\n",
    "model_logi_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89355fb-1030-41d4-9d60-5c804f28ad54",
   "metadata": {},
   "source": [
    "- Plot a heatmap of the confusion matrix. Compute the accuracy on the training and test set; as well as the precision, recall, and f1 score of class 1. How do your metrics compare to your model without cross-validation? **1 point**\n",
    "\n",
    "*Note*: You can, but not have to, create a function to calculate your evaluation metrics since we will perform the same operation later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9852a9d1-6262-4b70-affc-42fc2484f8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "plt.figure(figsize=(3, 2.5))\n",
    "sns.heatmap(confusion_matrix(y_test, model_logi_cv.predict(X_test)), annot=True, cmap='Blues', fmt='.4g')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fa2449-f2ac-43c1-91c2-a9405552c8ae",
   "metadata": {},
   "source": [
    "Let's create a function to compute the accuracy on training set and test set, as well as precision, recall, and f1 score of class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de44210-910b-447a-8ee5-feebafc2cb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_metrics(model, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"This function returns the accuracy on training set and test set, \n",
    "    as well as precision, recall, and f1 score of class 1,\n",
    "    of a classifier\"\"\"\n",
    "    # Accuracy on the training set\n",
    "    train_accuracy = model.score(X_train, y_train)\n",
    "    # Accuracy on test set\n",
    "    test_accuracy = model.score(X_test, y_test) \n",
    "    # Prediction\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Precision\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    # Recall\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    # f1\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    # Return output\n",
    "    return train_accuracy, test_accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efa9de8-956e-45a2-b3fe-a798b1bf93f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics model with cross validation\n",
    "model_logi_cv_metrics = classification_metrics(model_logi_cv, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Gather results in a dataframe:\n",
    "model_logi_metrics = [acc_logi_train, acc_logi_test, precision_logi, recall_logi, f1_logi]\n",
    "model_compar = pd.DataFrame(model_logi_metrics,\n",
    "                    index = ['Train accuracy', 'Test accuracy', 'Precision', 'Recall', 'f1'], \n",
    "                    columns=['Logistic regression'])\n",
    "model_compar['Logistic regression CV']=model_logi_cv_metrics\n",
    "model_compar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee1a976-5e89-4b13-abda-a25884454901",
   "metadata": {},
   "source": [
    "We obtain exactly the same results as before, except for the accuracy on the training set. The reason is that, since we have no overfitting, our model performs best without regularization. Hence, in both case, the penalty parameter for the regularization is low, and our optimal solution is almost not influenced by the regularization. For instance, we can check the coefficients of the features in the decision function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5df17fd-3ddc-4c47-a3c6-c1ac8236d722",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_models = pd.DataFrame(model_logi.coef_.flatten(), \n",
    "                            columns = ['Logistic regression'],\n",
    "                            index = X.columns)\n",
    "coeff_models['Logistic regression CV'] = model_logi_cv.coef_.flatten()\n",
    "coeff_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c37554-92a3-44b3-83ec-39fd76a16b39",
   "metadata": {},
   "source": [
    "### Question 9: KNN classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e829a37-268e-4310-9b51-d868020e1488",
   "metadata": {},
   "source": [
    "- Build and train a KNN classifier with parameters `n_neighbors=7`, `p=2`, `weights='uniform'` **1 point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ead0216-3239-4a1b-9bc3-00f8601628a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up our model\n",
    "model_kNN = KNeighborsClassifier(n_neighbors=7, p=2, weights='uniform')\n",
    "\n",
    "# Fit our model\n",
    "model_kNN.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b09b651-b03a-4cfc-b514-a823c6914ca5",
   "metadata": {},
   "source": [
    "- Plot a heatmap of the confusion matrix. Compute the accuracy on the training and test set; as well as the precision, recall, and f1 score of class 1. How do your metrics compare to your previous models? **1 point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522f3f82-bb0e-4781-a625-fa203af80338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "plt.figure(figsize=(3, 2.5))\n",
    "sns.heatmap(confusion_matrix(y_test, model_kNN.predict(X_test)), annot=True, cmap='Blues', fmt='.4g')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9accce5-d52d-44f4-a006-8b4b1f4885f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "model_kNN_metrics = classification_metrics(model_kNN, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Add to dataframe\n",
    "model_compar['KNN classifier']=model_kNN_metrics\n",
    "model_compar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef82fc98-fc2f-4ade-96b8-d7575e391432",
   "metadata": {},
   "source": [
    "The accuracy, precision, recall, and f1 increased. We are on the right track! That being said, the number of false positive did not change much (19 vs 21 before). The improvement is mostly due to better prediction of class 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b12db0-a203-4c0e-8976-7e4035a6ea8e",
   "metadata": {},
   "source": [
    "- Use `GridSearchCV` to explore different parameters for your model: `n_neighbors` between 1 and 11, `p` between 1 and 3, and `weights` either 'uniform' or 'distance' **1 point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c99ee6b-c812-4672-9ce5-a98c79a25c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters to test\n",
    "grid = {'n_neighbors':np.arange(1,12),     # array from 1 to 11 neighbors\n",
    "        'p':np.arange(1,3),                # array from 1 to 3, distance metrics\n",
    "        'weights':['uniform','distance']   # weights\n",
    "       }\n",
    "\n",
    "# Define and fit model\n",
    "knn = KNeighborsClassifier()\n",
    "knn_cv = GridSearchCV(knn, grid, cv=7)\n",
    "knn_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print results\n",
    "print(\"Hyperparameters:\", knn_cv.best_params_)\n",
    "print(\"Best model: \", knn_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef17736-e4de-477a-9a08-ac5afa8cb29f",
   "metadata": {},
   "source": [
    "- For your \"optimal\" model, compute the accuracy on the training and test set; as well as the precision, recall, and f1 score of class 1. How do your metrics compare to your previous models? **1 point** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e5e182-ecd4-4bba-8605-5a27df95ef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "model_kNN_cv_metrics = classification_metrics(knn_cv.best_estimator_, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Add to dataframe\n",
    "model_compar['KNN with Grid Search']=model_kNN_cv_metrics\n",
    "model_compar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fcaac0-d4fe-4d05-b74a-1eca2f96a22b",
   "metadata": {},
   "source": [
    "Interestingly, the precision increased while the recall stayed constant. We can check the confusion matrix to confirm that the number of false positive decreased:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2447f4-d8c3-4407-9fff-2c4528c1a315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "plt.figure(figsize=(3, 2.5))\n",
    "sns.heatmap(confusion_matrix(y_test, knn_cv.predict(X_test)), annot=True, cmap='Blues', fmt='.4g')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dc258a-d7cb-46da-a8cb-c3749a6bbe03",
   "metadata": {},
   "source": [
    "### Question 10: Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b267fafa-a5b4-4759-a6ec-9b95ef00e3ff",
   "metadata": {},
   "source": [
    "- Build and train a Decision Tree with parameters `criterion = 'gini'`, `max_depth = 3` **1 point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ce7ca3-5d8a-4e8a-b1b2-f310847373fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model \n",
    "model_tree = DecisionTreeClassifier(criterion = 'gini', max_depth = 3)\n",
    "\n",
    "# Fit model\n",
    "model_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e154e70d-e2b8-4a8b-b6f6-a53ddbfba37d",
   "metadata": {},
   "source": [
    "- Plot a heatmap of the confusion matrix. Compute the accuracy on the training and test set; as well as the precision, recall, and f1 score of class 1. How do your metrics compare to your previous models? **1 point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1997aca-cbf3-4a23-bf65-bcdd15293d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "plt.figure(figsize=(3, 2.5))\n",
    "sns.heatmap(confusion_matrix(y_test, model_tree.predict(X_test)), annot=True, cmap='Blues', fmt='.4g')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4813c7-85a7-41a0-8c4d-fcc231e50fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "model_tree_metrics = classification_metrics(model_tree, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Add to dataframe\n",
    "model_compar['Decision Tree']=model_tree_metrics\n",
    "model_compar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aba0ff-4317-4c7f-a80c-aca303f40e0a",
   "metadata": {},
   "source": [
    "It keeps getting better! Our accuracy on the test set is quite good, 94%, and we only have 9 false positive, resulting in a precision of 91%. The recall is now also above 50%, i.e., we have more true positive than false negative. Note that we shouldn't be surprised by these good results. Indeed, for the water to be safe, it requires pollutants and microorganisms to be below a certain level. It's exactly a task for a decision classifier!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc151dd-9582-4c76-bde6-4d9a0dea9c11",
   "metadata": {},
   "source": [
    "- Visualize your Decision Tree **1 point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e817f98-e0e1-4753-8a00-a81f545a93e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree plot\n",
    "plt.figure(figsize=(20,7))\n",
    "plot_tree(model_tree, feature_names= X.columns, filled=True, fontsize=12)\n",
    "plt.title('Decision Tree visualization', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bc0cbf-3764-4de3-aef6-d31233979395",
   "metadata": {},
   "source": [
    "Our tree is using the aluminium content as first split, and then proceed with aluminium and cadmium at the second level, and so on. One leaf has more observations belonging to class 1 (in blue). It is obtained for low values of aluminium, cadmium, and perchlorate. \n",
    "\n",
    "Note: the negative values are because we scaled our features using StandardScaler()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacfc59f-7aa0-4030-9ef0-58a051be89e7",
   "metadata": {},
   "source": [
    "- Use `GridSearchCV` to explore different parameters for your model: `criterion` either 'gini' or 'entropy' and `max_depth` between 1 and 7 **1 point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abab96a6-d754-4e5b-9e8c-f756760a2f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters to test\n",
    "grid_tree = {'criterion':['gini','entropy'] ,     # criterion\n",
    "        'max_depth':np.arange(1,8),               # array from 1 to 7, maximum depth\n",
    "       }\n",
    "\n",
    "# Define and fit model\n",
    "dec_tree = DecisionTreeClassifier()\n",
    "dec_tree_cv = GridSearchCV(dec_tree, grid_tree, cv=5)\n",
    "dec_tree_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print results\n",
    "print(\"Hyperparameters:\", dec_tree_cv.best_params_)\n",
    "print(\"Best model:\", dec_tree_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf7a522-280b-4cc1-8893-81ae00092957",
   "metadata": {},
   "source": [
    "- For your \"optimal\" model, compute the accuracy on the training and test set; as well as the precision, recall, and f1 score of class 1. How do your metrics compare to your previous models? **1 point** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d57ad79-6c5d-4385-8b36-7141cf54801d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "model_tree_cv_metrics = classification_metrics(dec_tree_cv.best_estimator_, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Add to dataframe\n",
    "model_compar['Tree with Grid Search']=model_tree_cv_metrics\n",
    "model_compar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1307c3-f2b9-4ce3-88cc-4bd8ad2b6f47",
   "metadata": {},
   "source": [
    "The model obtained with Grid Search has a depth of 7 and is using \"entropy\" instead of \"gini\". Hence, the accuracy on test set increases to 96.5%. The recall jumps to 75% while the precision stays more or less the same, which means our model got better at predicting class 1 (less false negative), but not at avoiding false positive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0633a696-b427-4772-9a8d-b16605084f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "plt.figure(figsize=(3, 2.5))\n",
    "sns.heatmap(confusion_matrix(y_test, dec_tree_cv.predict(X_test)), annot=True, cmap='Blues', fmt='.4g')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
