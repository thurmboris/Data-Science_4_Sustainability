{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82fd0c24-9cbd-4f4c-be86-ca94aff9ed23",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/thurmboris/Data-Science_4_Sustainability/blob/main/06_Classification/06_Classification.ipynb\" target=\"_blank\" rel=\"noopener\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dc4475-7f7d-4457-8762-bb031a0629b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Import to load arff file from url\n",
    "from scipy.io import arff\n",
    "import urllib.request\n",
    "import io \n",
    "\n",
    "# Sklearn import\n",
    "from sklearn.model_selection import train_test_split # Splitting the data set\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler # Normalization and standard scaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder # Label and 1-hot encoding\n",
    "from sklearn.linear_model import LogisticRegression # Logistic regression model\n",
    "from sklearn.linear_model import LogisticRegressionCV # Logistic regression with cross-validation\n",
    "from sklearn.metrics import accuracy_score  # Accuracy\n",
    "from sklearn.metrics import confusion_matrix # Confusion matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score  # Precision, recall, and f1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a844a8c0-078c-4946-8927-e570469c601c",
   "metadata": {},
   "source": [
    "# Classification: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9984e553-36af-42c8-9522-dd090686c913",
   "metadata": {},
   "source": [
    "<img src='https://i.postimg.cc/QxntZgdL/Supervised-Learning.jpg' width=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4392fab0-671b-45ea-b27a-61a797c0e090",
   "metadata": {},
   "source": [
    "## Content\n",
    "\n",
    "The goal of this walkthrough is to provide you with insights on classification, focusing on one technique called logistic regression. After presenting the main concepts, you will be introduced to the techniques to implement the algorithms in Python. Finally, it will be your turn to practice, using an application on forest fires. \n",
    "\n",
    "This notebook is organized as follows:\n",
    "- [Background](#Background)\n",
    "    - [Objective](#Objective)\n",
    "    - [Examples of classification](#Examples-of-classification)\n",
    "    - [Logistic regression model](#Logistic-regression-model)\n",
    "        - [Logistic Loss function](#Logistic-Loss-function)\n",
    "- [Implementation](#Implementation)\n",
    "    - [Load and discover dataset](#Load-and-discover-dataset)\n",
    "    - [Splitting the dataset](#Splitting-the-dataset)\n",
    "    - [Rescaling](#Rescaling)\n",
    "    - [Building and training our classifier](#Building-and-training-our-classifier)\n",
    "    - [Using the classifier to make prediction](#Using-the-classifier-to-make-prediction)\n",
    "    - [Evaluating our classifier](#Evaluating-our-classifier)\n",
    "        - [Accuracy](#Accuracy)\n",
    "        - [Confusion matrix](#Confusion-matrix)\n",
    "        - [Precision and Recall](#Precision-and-Recall)\n",
    "   - [Adding cross-validation](#Adding-cross-validation)\n",
    "   - [Visualizing our model: Decision boundary](#Visualizing-our-model:-Decision-boundary)\n",
    "- [Your turn](#Your-turn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7763984b-c9d6-43b0-ba06-fd749431aa32",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "### Objective\n",
    "\n",
    "We now move from regression another important branch of machine learning: classification. As the name indicates, the idea is to classify items of a dataset into **predefined classes** for which labelled data is already available.\n",
    "\n",
    "Classification is similar to regression, but instead of predicting a continuous target, classification algorithms attempt to apply a discrete number of labels or classes to each observation. \n",
    "\n",
    "While in a regression the targets are generally numerical and continuous-valued, oftentimes the targets in classification are categorical.  \n",
    "\n",
    "However, classification can be applied in settings where the target is numerical. For example, we might want to predict whether the unemployment rate for a country will be low, medium, or high, but do not care about the actual number. In such cases, determining the \"optimal\" way to categorize our target variable might require some creativity, and it is important to properly justify our assumptions. \n",
    "\n",
    "Finally, note that many problems can be written either as classification or regression. Hence, many ML algorithms have variants that perform regression or classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5292f5e7-73c2-41f3-af5f-17d4dcbe9fd9",
   "metadata": {},
   "source": [
    "### Examples of classification\n",
    "\n",
    "- Image classification: e.g., is this a cat or not?\n",
    "- Audio classification: identify bird species from birdsong\n",
    "- Labeling emails: is it a spam or not? \n",
    "- Risky or safe loan application: should a bank provide a loan to applicant or not?\n",
    "- Prediction of customer behaviour: will a customer buy this new product or not?  \n",
    "- Prediction of economic performance of a country: will there be a recession or not?  \n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251e9265-3d22-4a07-8838-23b32fce472f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Logistic regression model\n",
    "\n",
    "Suppose we have *n* observations of an outcome $\\boldsymbol{y}$ and *d* associated features $\\boldsymbol{x_1}$, $\\boldsymbol{x_2}$, ... , $\\boldsymbol{x_d}$ (note that $\\boldsymbol{y}$, $\\boldsymbol{x_1}$, ..., $\\boldsymbol{x_d}$ are vectors):\n",
    "\n",
    "| | Outcome | Feature 1 | Feature 2 | ... | Feature d |\n",
    "|:-------|:----------:|:----------:|:----------:|:----------:|:----------:|\n",
    "| Observation 1 | $y_1$ | $x_{11}$ | $x_{12}$ | ... | $x_{1d}$ |\n",
    "| Observation 2 | $y_2$ | $x_{21}$ | $x_{22}$ | ... | $x_{2d}$ |\n",
    "| ... | ... | ... | ... | ... | ... |\n",
    "| Observation n | $y_n$ | $x_{n1}$ | $x_{n2}$ | ... | $x_{nd}$ |\n",
    "\n",
    "We will focus on binary classification for now. In other words, our outcome can take two values, 0 and 1, which represent two classes (e.g., cat or dog, spam email or not, risky or safe loan, etc.).\n",
    "\n",
    "Remember when we did multivariate linear regression, we assumed that our model function $f_{\\text{mv}}$, i.e., our prediction, was a linear combination of our features. For each observation $i$, we assumed:\n",
    "$$f_{\\text{mv}}(\\boldsymbol{X_{i*}}, \\boldsymbol{w}):=w_0 + w_1 x_{i,1} +  w_2 x_{i,2} + ... +  w_d x_{i,d}$$\n",
    "with $\\boldsymbol{w}=(w_0, w_1, ..., w_d)$ the vector of weights, and $\\boldsymbol{X}=[\\boldsymbol{x_1}$, ... , $\\boldsymbol{x_d}]$ the matrix of feature variables.\n",
    "\n",
    "For each observation, our true outcome was $y_i = f_{\\text{mv}}(\\boldsymbol{X_{i*}}, \\boldsymbol{w}) + \\epsilon_i$, and our goal was to minimize the errors. \n",
    "\n",
    "In this setting, our model function $f_{\\text{mv}}$ can take any values. It is thus suited when our outcome is continuous. However, with binary classification, we are dealing with discrete values, and more precisely with 0 and 1. How can we modify our model to obtain better prediction?\n",
    "\n",
    "The idea of logistic regression is to transform the predictions obtained with a linear regression such that the predictions are between 0 and 1. To do so, we rely on the [Sigmoid (logistic) function](https://en.wikipedia.org/wiki/Sigmoid_function):\n",
    "\n",
    "$$S(x) = \\frac{1}{1 + e^{-x}}$$\n",
    "\n",
    "<center>\n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/1280px-Logistic-curve.svg.png' width=\"300\">\n",
    "</center>\n",
    "\n",
    "Source: Qef, from [Wikipedia Logistic Curve plot](https://commons.wikimedia.org/wiki/File:Logistic-curve.svg)\n",
    "\n",
    "With logistic regression, we apply the sigmoid function to the output of the multivariate regression model. Let $f_{\\text{logi}}$ be the prediction function of a logistic regression, we have:\n",
    "\n",
    "$$f_{\\text{logi}}(\\boldsymbol{X_{i*}}, \\boldsymbol{w}):= \\frac{1}{1 + e^{-(w_0 + w_1 x_{i,1} +  w_2 x_{i,2} + ... +  w_d x_{i,d})}}$$\n",
    "\n",
    "$f_{\\text{logi}}$ represents the probability that a given observation belongs to class 1, i.e., $y_i=1$:\n",
    "- We predict that the observation belongs to class 1 when $f_{\\text{logi}}(\\boldsymbol{X_{i*}}, \\boldsymbol{w}) \\geq 0.5$, i.e., when $w_0 + w_1 x_{i,1} +  w_2 x_{i,2} + ... +  w_d x_{i,d} \\geq 0$;\n",
    "- Reciprocally, we predict that the observation belongs to class 0 when $f_{\\text{logi}}(\\boldsymbol{X_{i*}}, \\boldsymbol{w})<0.5$, i.e., $w_0 + w_1 x_{i,1} +  w_2 x_{i,2} + ... +  w_d x_{i,d}<0$.\n",
    "\n",
    "Now our problem is the same as before: we want to minimize the errors of our model, learning the weights $w_0$, $w_1$, ..., $w_d$ from our data. To do so, we are minimizing our loss function... but which one? We will explore one option below.\n",
    "\n",
    "*Note*: In the case of multiclass logistic regression, the idea is the same: we need to transform the output of our multivariate model. However, instead of using the sigmoid function, we are applying the [Softmax function](https://en.wikipedia.org/wiki/Softmax_function), a generalization of the sigmoid function.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edb4df8-98f9-4903-ae42-65e57e0d8a84",
   "metadata": {},
   "source": [
    "#### Logistic Loss function \n",
    "\n",
    "For linear regression, we used the Least Squared Error as loss function:\n",
    "\n",
    "$$ \\min_\\boldsymbol{w} \\sum_{i=1}^n (y_i - f_{\\text{mv}}(\\boldsymbol{X_{i*}}, \\boldsymbol{w}))^2 $$\n",
    "\n",
    "Can we use the same for logistic regression? No! Indeed, using Least Squared Error with our new prediction function $f_{\\text{mv}}$ would result in a non-convex graph, which is not ideal for our minimization problem since we could be stuck in local minima:\n",
    "\n",
    "<center>\n",
    "<img src='https://miro.medium.com/v2/resize:fit:1100/format:webp/1*3o9_XoQP4TaceYPRZVHlxg.png' width=\"300\">\n",
    "</center>\n",
    "\n",
    "Source: Issam Laradji, [Non-convex Optimization](https://www.cs.ubc.ca/labs/lci/mlrg/slides/non_convex_optimization.pdf)\n",
    "\n",
    "So which loss function can we use? Ideally, we want to assign more punishment when predicting 1 while the actual value is 0 and when predicting 0 while the actual value is 1. One such function is the... **Logistic Loss**:\n",
    "\n",
    "$$L(\\boldsymbol{y}, \\boldsymbol{X}, \\boldsymbol{w})= -\\frac{1}{n} \\sum_{i=1}^n [y_i \\log(f_{\\text{logi}}(\\boldsymbol{X_{i*}}, \\boldsymbol{w})) + (1-y_i) \\log(1-f_{\\text{logi}}(\\boldsymbol{X_{i*}}, \\boldsymbol{w}))] $$\n",
    "\n",
    "Let's decompose our function to understand a bit more how it works. For each observation $i$, the cost is: \n",
    "\n",
    "$$\\text{Cost}_i = - y_i \\log(f_{\\text{logi}}(\\boldsymbol{X_{i*}}, \\boldsymbol{w})) - (1-y_i) \\log(1-f_{\\text{logi}}(\\boldsymbol{X_{i*}}, \\boldsymbol{w}))$$\n",
    "\n",
    "- When $y_i = 1$, $\\text{Cost}_i = - \\log(f_{\\text{logi}}(\\boldsymbol{X_{i*}}, \\boldsymbol{w}))$. Hence, if our predicted probability is 1, we have $\\text{Cost}_i=0$, i.e., no cost. However, when our predicted probability is approaching 0, our cost goes to infinity (because the logarithm goes to minus infinity when we get closer to zero).\n",
    "- When $y_i = 0$, $\\text{Cost}_i = - \\log(1-f_{\\text{logi}}(\\boldsymbol{X_{i*}}, \\boldsymbol{w}))$, and it works the other way around. If our predicted probability is zero, the cost is zero, but when our predicted probability is approaching 1, our cost goes to infinity.\n",
    "\n",
    "<center>\n",
    "<img src='https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_NeTem-yeZ8Pr9cVUoi_HA.png' width=\"400\">\n",
    "</center>\n",
    "\n",
    "Source: Shuyu Luo, [Loss Function (Part II): Logistic Regression](https://towardsdatascience.com/optimization-loss-function-under-the-hood-part-ii-d20a239cde11)\n",
    "\n",
    "The Logistic Loss not only punishes errors with a very large cost, it is also convex. Hence, we can still apply Gradient Descent, Newton's Method, and other optimization algorithms!\n",
    "\n",
    "To learn more:\n",
    "- [Loss Function (Part II): Logistic Regression](https://towardsdatascience.com/optimization-loss-function-under-the-hood-part-ii-d20a239cde11), by Shuyu Luo, Published in Towards Data Science\n",
    "- [Understanding the log loss function](https://medium.com/analytics-vidhya/understanding-the-loss-function-of-logistic-regression-ac1eec2838ce), by Susmith Reddy, Published in Analytics Vidhya\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce878d70-296b-4ce2-9a05-a5d0410d79e1",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "We are already familiar with the **sklearn** library, when we implemented regression algorithms last week ([Documentation](https://scikit-learn.org/stable/index.html)). We will keep on using this library to implement a logistic regression.\n",
    "\n",
    "For the walkthough we will use a **dataset on wine quality**. As usual, you can find it in the /data folder.\n",
    "\n",
    "<img src='https://assets.pbimgs.com/pbimgs/rk/images/dp/wcm/202145/0002/schott-zwiesel-classico-wine-glasses-c.jpg' width=\"300\">\n",
    "\n",
    "The wine data set consists of 11 different parameters of wine such as alcohol content, acidity, and pH, which were measured for several wine samples from the North of Portugal.\n",
    "\n",
    "Source: P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. Modeling wine preferences by data mining from physicochemical properties. In *Decision Support Systems*, Elsevier, 47(4):547-553, 2009. Dataset obtained from UCI Machine Learning repository, [Wine Quality Data Set](https://archive.ics.uci.edu/ml/datasets/wine+quality). \n",
    "\n",
    "These wines were derived from different cultivars; therefore there have different quality, as a score between 0 and 10. We grouped the wines into two quality classes: 0 and 1, representing respectively  \"poor quality\" (score 0-5), and \"good quality\" (score 6-10).\n",
    "\n",
    "Our goal here is to find a model that can predict the class of wine given the 11 measured parameters, and find out the major differences among the two classes.\n",
    "\n",
    "Ok, let's go!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751923ff-7b61-4ab9-af76-1b6b98b9e1f7",
   "metadata": {},
   "source": [
    "### Load and discover dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c288953-a267-4f5c-9271-40079cb5fea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/thurmboris/Data-Science_4_Sustainability/main/data/wine-quality-red.csv\"\n",
    "wines = pd.read_csv(url).drop_duplicates().dropna() # drop duplicates and NaN values\n",
    "\n",
    "# Display a sample of the data\n",
    "display(wines.head())\n",
    "\n",
    "# Print columns\n",
    "print(wines.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef78718-ca7e-47fc-9099-348f12837f8c",
   "metadata": {},
   "source": [
    "Note that we only have numerical variables, and thus won't need to encode categorical variables. \n",
    "\n",
    "However, we will need to rescale our features since, for instance, chlorides values are lower than 1 while sulfur dioxide can attain a value of 289:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185e5eaf-6304-4801-abd4-b629e61de2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wines.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0409233c-f2d4-48fa-a560-c9f45b0c4c64",
   "metadata": {},
   "source": [
    "We now define our features - all wine parameters - and our target variable - the wine quality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66708daf-fce1-4eb2-84ca-709c3b556ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "X = wines.drop(columns='quality')\n",
    "y = wines['quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1dffca-cb02-4261-81df-b0729f88d975",
   "metadata": {},
   "source": [
    "We know check how many observations we have for each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5976a37-8e49-4f00-8bfb-76f3a5060e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of observations (rows) corresponding to each value \n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16d8f2c-5bd6-441c-96a8-3d1965171e68",
   "metadata": {},
   "source": [
    "We have 719 \"good\" wines and 640 \"poor\" quality wines. The number of observations for each class influence the quality of our predictions. Here, our dataset is reasonably balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da1d609-f411-4205-9026-f452795d8dac",
   "metadata": {},
   "source": [
    "### Splitting the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e022dc7-61eb-41cd-b112-8f099274231c",
   "metadata": {},
   "source": [
    "As always, the first step is to split our data into random training and test subsets. Recall that the training set is used to learn the parameters of our model while the test set is used to evaluate our predictions.\n",
    "\n",
    "We use the `train_test_split` ([Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)) of sklearn, imported with the following line of code (already done at the beginning of the notebook):\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split \n",
    "```\n",
    "\n",
    "The test size here is of 25% of the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bed44fb-c22b-4bc3-8c28-5bc1d2f469cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data set into a train and a test data sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0, shuffle=True)\n",
    "\n",
    "print(f\"The training set has {X_train.shape[0]} observations, and the test set has {X_test.shape[0]} observations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d607ddfc-bfab-4834-a4fb-a54e93b12114",
   "metadata": {},
   "source": [
    "### Rescaling\n",
    "\n",
    "When we have a dataset with features that have very distinct ranges, we might get biased results. We want the features to be in the same or similar range, which also helps the interpretation of the model parameters (weights). \n",
    "\n",
    "We therefore **normalize** the data. It involves transforming all values for a specific attribute so that they fall within a small specified range. We can use `StandardScaler()`, ([Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)) `MinMaxScaler()` ([Documentation](https://scikit-learn.org/0.15/modules/generated/sklearn.preprocessing.MinMaxScaler.html)) or others for normalization.\n",
    "\n",
    "In our example we will normalize both our **train AND test data** using `MinMaxScaler()`. Here is the import line:\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "```\n",
    "\n",
    "For each observation $x_{ij}$, with $i$ the observation (row) and $j$ the feature (column), the MinMax Scaler applies the following transformation:  \n",
    "$$x_{scaled,ij}=\\frac{x_{ij} - \\min(\\boldsymbol{x_j})}{\\max(\\boldsymbol{x_j})-\\min(\\boldsymbol{x_j})}$$\n",
    "\n",
    "**IMPORTANT**: When you normalize the train data, you need to do the same modification (here normalization) to the test data. In other words, you train your scaler on your training set, and apply the same transformation to the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a107b7-f1cb-4b31-a20f-ecdc9b61b7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "scaler.fit(X_train) # here the scaler learns the min and max of each attribute from the training set\n",
    "\n",
    "# Transform the train and the test set\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "## Note that the fit and transform steps can be merged into one for the training set:\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0a1b43-4e06-4b70-8a83-c5e58d99e2d7",
   "metadata": {},
   "source": [
    "### Building and training our classifier\n",
    "\n",
    "To predict the class of our target variable we use a logistic regression. The sklearn module is called `LogisticRegression()` ([Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)). Here is the import line:\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "```\n",
    "\n",
    "Note that L2-regularization is applied by default. By specifying the argument *penalty*, you can specify the regularization techniques, namely 'l1', 'l2', 'elasticnet', or None. \n",
    "\n",
    "You can also specify the *solver*. By default, 'lbfgs' is used, which stands for [Limited-memory Broyden–Fletcher–Goldfarb–Shanno](https://en.wikipedia.org/wiki/Limited-memory_BFGS). \n",
    "Note that the choice of the algorithm depends on the penalty chosen. You can refer to the documentation for insights on the choice of solver/penalty depending on your problem and data.\n",
    "\n",
    "**A short note on solver:**\n",
    "L-BFGS approximates the Broyden–Fletcher–Goldfarb–Shanno algorithm ([BFGS](https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm)), which is based on [Newton's method](https://en.wikipedia.org/wiki/Newton%27s_method_in_optimization), an alternative to Gradient Descent. While the Gradient Descent rely on the gradient (first-order derivatives) to update our parameters, Newton's method also makes use of the [Hessian matrix](https://en.wikipedia.org/wiki/Hessian_matrix), i.e., the second-order derivatives. Newton's method generally converges faster than Gradient Descent. However, Newton's method is computationally-expensive and the Hessian might not even exist. Hence, numerical methods called [Quasi-Newton](https://en.wikipedia.org/wiki/Quasi-Newton_method), such as BFGS, have been developed to solve optimization problems.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e909b23-c4db-408d-8bd9-3267b8281632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Set up our model\n",
    "model = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=1000)\n",
    "\n",
    "# 2. Fit our model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e935629-c646-44e6-8491-ecbf664b8e75",
   "metadata": {},
   "source": [
    "After fitting the model, we can easily retrieve the values of the different weights coefficients: the intercept with `.intercept_`, and the weights of each feature with `.coef_.flatten()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a615f08f-a1b1-40df-b897-d2e01edc9b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe with the intercept and coefficients (weights) of the logistic model\n",
    "model_coeff = pd.DataFrame(np.concatenate((model.intercept_, model.coef_.flatten())), \n",
    "                     index=[\"Intercept\"] + list(X.columns.values),\n",
    "                     columns=['Coefficients logistic model'])\n",
    "model_coeff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e583fd-4373-47b2-a70b-23ad6e621981",
   "metadata": {},
   "source": [
    "It seems like the level of alcohol and volatile acidity were the most important features to predict the wine quality, at least in our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4185d54b-63ca-41d0-a48a-2b4ea7930baa",
   "metadata": {},
   "source": [
    "### Using the classifier to make prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5554cc06-ed5f-4b9d-a477-9943e551cf7a",
   "metadata": {},
   "source": [
    "Once our model has been trained, we can use `predict()` to predict new values. We predict the values from the test set to then evaluate the model, estimating the accuracy of our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2883ebcd-bcfc-4bab-85ef-ad0ea8d78778",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1941fb-44bb-4abf-b9d8-0555a499fa6d",
   "metadata": {},
   "source": [
    "We can even access the probabilities that one observation belongs to one class or the other with `predict_proba()`. The largest probability determines the predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8bf5e9-f35c-44f2-9ce0-612bfe5bd53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe with probabilities that our first 5 observations belong to each class\n",
    "model_proba = pd.DataFrame(model.predict_proba(X_test)[0:4], \n",
    "                     columns=['Probability poor-quality wine', 'Probability good wine'])\n",
    "model_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc6921d-d075-4f8c-9ef8-e7ebdb150513",
   "metadata": {},
   "source": [
    "###  Evaluating our classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2af149f-9cf2-45a1-9b15-279ecf50ef0a",
   "metadata": {},
   "source": [
    "We will now evaluate the performance of our classifier using several metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a3e15a-dd3f-40ec-afa7-782e5ba2fc5c",
   "metadata": {},
   "source": [
    "#### Accuracy\n",
    "\n",
    "Perhaps the most intuitive classification metric is *accuracy*, which is the fraction of correct vs total predictions:\n",
    "\n",
    "$$ \\mathrm{Accuracy} = \\frac{\\# \\mathrm{\\, correct \\, predictions}}{\\# \\mathrm{\\, total \\, predictions}} $$\n",
    "\n",
    "For a sklearn classifier, this can be computed using the `score` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81238743-9b28-410e-8f6a-f0934d6c8f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy on the test set\n",
    "print('Accuracy of Logistic regression classifier on test set: {:.2f}'\n",
    "     .format(model.score(X_test, y_test)))\n",
    "\n",
    "# Accuracy on the training set\n",
    "print('Accuracy of Logistic regression classifier on training set: {:.2f}'\n",
    "     .format(model.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8747b9-9300-4568-9144-5011d0bd7d57",
   "metadata": {},
   "source": [
    "Alternatively, we could use the `accuracy_score` module, imported with the following line of code:\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import accuracy_score\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4385d7cb-2e5e-44dd-b6d6-1895303f0d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accurary of Logistic regression classifier on test set: {accuracy_test :.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4376c9e-5a5d-4d49-a30b-9b98d4b6f0b4",
   "metadata": {},
   "source": [
    "When the testing accuracy is much lower than the training accuracy, we have an overfitting issue. Reciprocally, when the testing accuracy is similar to or higher than the training accuracy, the model might be underfitting, and we could consider either using a more powerful model or adding additional\n",
    "features.\n",
    "\n",
    "Our testing accuracy is 72%. Is that good? It depends! The quality of our prediction depends on the distribution of class in our original data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ba86eb-3539-4b63-864a-c9643c7755bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts().plot.bar(color=['purple', 'blue'], grid=False)\n",
    "plt.ylabel('Number of observations')\n",
    "plt.title('Number of observations of each class in the wine dataset');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26719ec2-0d1f-4516-a1d0-94afd091365a",
   "metadata": {},
   "source": [
    "Imagine we have a naive classifier that always predict the majority class. We call the default rate (or base rate) the accuracy of this classifier, which is equal to the size of the most common class over the size of the full dataset:\n",
    "\n",
    "$$\\text{Default rate} = \\frac{\\# \\text{ most frequent class}}{\\# \\text{ total observations}}$$\n",
    "\n",
    "If the default rate is too high, then the classification can be biased, meaning that the data set has too many observations of one class compared to the other classes, and has hence more impact on the classification results. \n",
    "\n",
    "The accuracy of our classifier should be better than the default rate. Let's calculate this default rate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a06e9a-9230-4a7b-b3f7-b46caf19b7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the default rate\n",
    "quality_0 = wines.loc[wines[\"quality\"] == 0].shape[0]\n",
    "print('# occurrence of class 0: ', quality_0)\n",
    "quality_1 = wines.loc[wines[\"quality\"] == 1].shape[0]\n",
    "print('# occurence of class 1: ', quality_1)\n",
    "defaultrate = max(quality_0, quality_1)/(wines[\"quality\"].shape[0])\n",
    "print(f'Default rate = {defaultrate:0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfc42bc-843e-4872-b1f8-df31dd2b34bf",
   "metadata": {},
   "source": [
    "Our default rate is about 52.9% while our classifier accuracy is 72.4%. Not too bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d4d413-7a87-4590-a54f-cc5b6d44bb8e",
   "metadata": {},
   "source": [
    "#### Confusion matrix\n",
    "\n",
    "The confusion matrix allows us to get more details on the performance of our model. It will allow us to see what our classification model is getting right and what types of errors it is making.\n",
    "\n",
    "Here is how a confusion matrix looks like: \n",
    "\n",
    "|   | Class 0 predicted  | Class 1 predicted  |    \n",
    "|---|---|---|\n",
    "| **Class 0 actual**  |  TN |FP   |    \n",
    "| **Class 1 actual**  | FN  | TP  |   \n",
    "\n",
    "\n",
    "where TP = true positive, FN = false negative, FP = false positive and TN = true negative. Here class 1 is considered the \"True\" class.\n",
    "\n",
    "We are using the `confusion_matrix` module of sklearn, imported with the following line of code:\n",
    "\n",
    "``` python\n",
    "from sklearn.metrics import confusion_matrix\n",
    "```\n",
    "\n",
    "It requires as input the true values and the predicted values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f11c82-0201-4916-93c2-7309f84f7f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7b9179-14f6-42cc-8715-6a9248f10007",
   "metadata": {},
   "source": [
    "To obtain a more visual representation, we will use `heatmap` from the `seaborn` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760b68ac-74a0-4f8a-8e53-c4e5bd1f7838",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, cmap='Blues', fmt='.4g')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc130704-0459-49be-8643-559f37b2c428",
   "metadata": {},
   "source": [
    "On the diagonal of the confusion matrix are our correct predictions, while the off-diagonal elements are incorrect predictions. We can thus quickly identify whether one class is driving down or up the accuracy results, or if the results are more balanced. \n",
    "\n",
    "Recall that the accuracy is the number of correct predictions divided by the number of incorrect predictions. Thus, the accuracy is the sum of the diagonal elements of the confusion matrix, divided by the total number of elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dadc4b-ec06-4b29-843b-1d37aacc10e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy on test set using sklearn: {:.6f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('Accuracy on test set by hand: {:.6f}'.format((113+133)/(113+133+45+49)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22860d3-e863-4045-b487-9ffbdc36093c",
   "metadata": {},
   "source": [
    "#### Precision and Recall\n",
    "\n",
    "In many contexts, the accuracy would be an appropriate way to evaluate a model, but in others, this would be insufficient.\n",
    "\n",
    "For example, suppose we want to use a classification model to predict the likelihood of someone having a rare, but serious health condition. If the condition is very rare (say it appears in 0.01% of the population), then a model that always predicts false would have 99.99% accuracy, but the false negatives could have large consequences. \n",
    "\n",
    "To capture such situations, we often use two other very common metrics: the *precision* and *recall*.\n",
    "\n",
    "Let class 1 represents our positive cases (\"true\" class), the confusion matrix is: \n",
    "\n",
    "|   | Class 0 predicted  | Class 1 predicted  |    \n",
    "|---|---|---|\n",
    "| **Class 0 actual**  |  TN | FP   |    \n",
    "| **Class 1 actual**  | FN  | TP  | \n",
    "\n",
    "- *Precision*: The number of true positives over the number of positive  predictions. Precision tells us how often the model was correct when it predicted true.\n",
    "\n",
    "$$\\text{Precision} = \\frac{\\# \\text{ true positives}}{\\# \\text{ predicted positives}} = \\frac{ \\text{TP}}{\\text{TP+FP}}$$\n",
    "\n",
    "- *Recall*: The number of true positives over the number of actual positives. Recall answers the question, “What fraction of the positives did we get correct?”  \n",
    "\n",
    "$$\\text{Recall} = \\frac{\\# \\text{ true positives}}{\\# \\text{ actual positives}} = \\frac{\\text{TP}}{ \\text{TP+FN}}$$ \n",
    "\n",
    "In many settings, both precision and recall are equally important and a compound metric known as the *F1-score* is used:\n",
    "\n",
    "$$\\text{F1} = 2 \\frac{\\text{precision} \\cdot \\text{recall}}{\\text{precision} + \\text{recall}}$$\n",
    "\n",
    "The F1 score is bounded between 0 and 1. It will only achieve a value of 1 if both precision and recall are exactly 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aec43ad-713a-48bb-8517-5768fe3c35e9",
   "metadata": {},
   "source": [
    "We will compute the precision using `precision_score` ([Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score)), the recall using `recall_score` ([Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score)), and the F1 score using `f1_score` ([Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score)). Here are the import lines:\n",
    "\n",
    "``` python\n",
    "from sklearn.metrics import precision_score \n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "```\n",
    "\n",
    "For a binary classifier, all metrics will report by default the scores associated with the positive class (i.e., with observations equal to 1). If we are interested in the results for another class, we can specify some parameters. For instance, the parameter `average = None` will return the scores of each class: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45baf3f7-da07-4ffd-b88d-56967671f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The precision for class 1 (good wines) is: {:0.3f}'.format(precision_score(y_test, y_pred)))\n",
    "print('The recall for class 1 is: {:0.3f}'.format(recall_score(y_test, y_pred)))\n",
    "print('The F1 score for class 1 is: {:0.3f}'.format(f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97534c50-3407-4bef-b79f-44da9ed81142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision of each class\n",
    "model_precision = precision_score(y_test, y_pred, average = None)\n",
    "# Recall of each class\n",
    "model_recall = recall_score(y_test, y_pred, average = None)\n",
    "# F1 score of each class\n",
    "model_f1 = f1_score(y_test, y_pred, average = None)\n",
    "\n",
    "# Visualize all results in a dataframe:\n",
    "model_eval = pd.DataFrame([model_precision, model_recall, model_f1],\n",
    "                    index = ['Precision', 'Recall', 'F1 score'], \n",
    "                    columns=['Class 0', 'Class 1'])\n",
    "model_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ef31e3-c610-4964-be00-9b54f4be1cad",
   "metadata": {},
   "source": [
    "Evaluating your classifier is key, and it depends on our objectives and on our data. You can find all the sklearn model evaluation metrics [here](https://scikit-learn.org/stable/modules/model_evaluation.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3592471e-12a9-4ef8-9085-d7b58cefeded",
   "metadata": {},
   "source": [
    "### Adding cross-validation\n",
    "\n",
    "We will see how the performance of our model evolves when implementing cross-validation technique. We are using the `LogisticRegressionCV()` module ([Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html#sklearn.linear_model.LogisticRegressionCV)), imported as follows:\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346e9465-2718-4f0d-b7c0-8b390e6c1610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up our model\n",
    "model_cv = LogisticRegressionCV(penalty='l2', solver='lbfgs', cv=5, max_iter=1000)\n",
    "\n",
    "# Fit our model\n",
    "model_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a47f105-c0ec-4539-8343-9bde6172e907",
   "metadata": {},
   "source": [
    "Let's check the accuracy of our new model and compare it to the previous one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b05c52-2d01-444a-87bd-6a65dfe55dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy on the test set\n",
    "model_cv_test_accuracy = model_cv.score(X_test, y_test) # Cross-validation model\n",
    "model_test_accuracy = model.score(X_test, y_test)       # Logistic regression\n",
    "# Accuracy on the training set\n",
    "model_cv_train_accuracy = model_cv.score(X_train, y_train) # Cross-validation model\n",
    "model_train_accuracy = model.score(X_train, y_train)       # Logistic regression\n",
    "# Gather results in a dataframe:\n",
    "models_accuracy = [[model_cv_test_accuracy, model_test_accuracy], \n",
    "                   [model_cv_train_accuracy, model_train_accuracy]]\n",
    "model_compar = pd.DataFrame(models_accuracy,\n",
    "                    index = ['Test accuracy', 'Train accuracy'], \n",
    "                    columns=['Cross-validation model', 'Logistic regression'])\n",
    "model_compar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbaaaf2-5845-4c20-b376-b5c3166085e3",
   "metadata": {},
   "source": [
    "The accuracy improved a bit. Let's have a look at the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bcf462-6c10-4bb0-b184-31b293babeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "confusion_cv = confusion_matrix(y_test, model_cv.predict(X_test))\n",
    "# Heatmap of confusion matrix\n",
    "sns.heatmap(confusion_cv, annot=True, cmap='Blues', fmt='.4g')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix with Cross Validation');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f987181-f5c1-47f7-aadd-df9b61c8bf98",
   "metadata": {},
   "source": [
    "We correctly predicted one additional observation from the class 0. Not a spectacular improvement but we'll take it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafd0a82-7600-499d-8e44-596201abc783",
   "metadata": {},
   "source": [
    "### Visualizing our model: Decision boundary\n",
    "\n",
    "Let's build a new classifier, only using two features, namely alcohol and volatile acidity. Our objective is to visualize the decision boundary, i.e., the line that splits our two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2c5806-e07d-40c8-a579-e4c92a25cf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features of interest\n",
    "X2 = X[['volatile acidity', 'alcohol']]\n",
    "\n",
    "# Split data set into a train and a test data sets\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X2, y, test_size=0.25, random_state=0, shuffle=True)\n",
    "\n",
    "# Set up our model\n",
    "model_2 = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=1000)\n",
    "\n",
    "# Fit our model\n",
    "model_2.fit(X_train_2, y_train_2)\n",
    "\n",
    "# Compute accuracy\n",
    "print('Accuracy of two-features classifier on test set: {:.2f}'\n",
    "     .format(model_2.score(X_test_2, y_test_2)))\n",
    "print('Accuracy of two-features classifier on training set: {:.2f}'\n",
    "     .format(model_2.score(X_train_2, y_train_2)))\n",
    "\n",
    "# Dataframe with the intercept and coefficients (weights) of the model\n",
    "model_2_coeff = pd.DataFrame(np.concatenate((model_2.intercept_, model_2.coef_.flatten())), \n",
    "                     index=[\"Intercept\"] + list(X2.columns.values),\n",
    "                     columns=['Coefficients 2-features model'])\n",
    "model_2_coeff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4b74db-56bf-4c6e-9fa0-eb4bac217e54",
   "metadata": {},
   "source": [
    "We now plot the decision boundary. \n",
    "\n",
    "Note that the decision boundary represents the points for which the probability to belong to class 0 is the same as the probability to belong to class 1. For such points, we have:\n",
    "\n",
    "$$w_0 + w_1 x_{i1} + w_2 x_{i2} =0 $$\n",
    "\n",
    "Reorganizing, we get:\n",
    "\n",
    "$$x_{i2} = - \\frac{w_0 + w_1 x_{i1}}{w_2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa06c7a-0b1a-4bac-9923-65271f93a25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Scatter plot of volatile acidity and alcohol, colored by their class\n",
    "scatter = ax.scatter(X2['volatile acidity'].values,  # values of volatile acidity on x-axis\n",
    "            X2['alcohol'].values,                    # values of alcohol on y-axis\n",
    "            c=y,                   # color class by class \n",
    "            edgecolors='k',        # black edge colors\n",
    "            cmap=plt.cm.Paired)    # color of markers: Paired colormap \n",
    "\n",
    "# Plot decision boundary \n",
    "x_vals = np.array(ax.get_xlim())    # array with x-axis limits\n",
    "y_vals = -(model_2.intercept_[0]+x_vals*model_2.coef_[0][0])/model_2.coef_[0][1]  # equation of decision boundary\n",
    "plt.plot(x_vals, y_vals, '--', c=\"red\")  # plot decision boundary in red color\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Wine volatile acidity content ')\n",
    "plt.ylabel('Wine alcohol content')\n",
    "plt.title('Decision boundary for classification model using two features')\n",
    "plt.legend(*scatter.legend_elements(),loc=\"lower right\", title=\"Classes\")\n",
    "\n",
    "# Display plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871268fc-dd62-45c0-b758-7c9919af1ca3",
   "metadata": {},
   "source": [
    "Let's interpret this graph. The red doted line shows the boundary between the two regions. Each observation above the line will belong to class 1, i.e., good wine, while each observation below the line will belong to class 0, i.e., poor quality wine. Furthermore, the closer a point is to the decision region boundary the more uncertain we are about the accuracy of the classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e135c63-0721-4ca1-8317-b27b835d7ac3",
   "metadata": {},
   "source": [
    "Let's test this, by creating two new points:\n",
    "- point A will have a volatile acidity of 1.2 and an alcohol content of 11.5\n",
    "- point B will have the same volatile acidity, but an alcohol content of 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187aff67-f5f8-4d43-831a-d2d1aeb5c99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Scatter plot of volatile acidity and alcohol, colored by their class\n",
    "scatter = ax.scatter(X2['volatile acidity'].values,  # values of volatile acidity on x-axis\n",
    "            X2['alcohol'].values,                    # values of alcohol on y-axis\n",
    "            c=y,                   # color class by class \n",
    "            edgecolors='k',        # black edge colors\n",
    "            cmap=plt.cm.Paired)    # color of markers: Paired colormap \n",
    "\n",
    "# Plot decision boundary \n",
    "x_vals = np.array(ax.get_xlim())    # array with x-axis limits\n",
    "y_vals = -(model_2.intercept_[0]+x_vals*model_2.coef_[0][0])/model_2.coef_[0][1]  # equation of decision boundary\n",
    "plt.plot(x_vals, y_vals, '--', c=\"red\")  # plot decision boundary in red color\n",
    "\n",
    "# Add new points\n",
    "plt.scatter(1.2, 11.5, c='red') # Point A\n",
    "plt.scatter(1.2, 13, c='red')   # Point B\n",
    "plt.text(1.23, 11.4, 'Point A')  # Point A label\n",
    "plt.text(1.23, 12.9, 'Point B')       # Point B label\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Wine volatile acidity content ')\n",
    "plt.ylabel('Wine alcohol content')\n",
    "plt.title('Decision boundary for classification model using two features')\n",
    "plt.legend(*scatter.legend_elements(),loc=\"lower right\", title=\"Classes\")\n",
    "\n",
    "# Display plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886527e8-e50b-4d57-bf84-a765ac45ecf9",
   "metadata": {},
   "source": [
    "We predict the class of each point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5753fd-aace-4b56-925e-7a9c355e0f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe with new points\n",
    "x_new= pd.DataFrame([[1.2, 11.5], [1.2,13]], columns=['volatile acidity', 'alcohol'])\n",
    "\n",
    "# Predicted class\n",
    "print('Point A belongs to class {}.'.format(model_2.predict(x_new)[0]))\n",
    "print('Point B belongs to class {}.'.format(model_2.predict(x_new)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fcfbbb-e64a-4bc8-a480-c91ac9e302cb",
   "metadata": {},
   "source": [
    "Finally, we can check the probabilities to belong to each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1359eda9-47ec-4ec7-9e2e-38fea835bdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe with probabilities to belong to each class\n",
    "x_new_proba = pd.DataFrame(model_2.predict_proba(x_new), \n",
    "                     index = ['A', 'B'],      \n",
    "                     columns=['Class 0', 'Class 1'])\n",
    "x_new_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2bb01d-0245-468e-bb31-9006ef915458",
   "metadata": {},
   "source": [
    "Point A is closer to the boundary decision line, hence, its probability to belong to class 0 (0.63) is lower than the probability of point B to belong to class 1 (0.76): the prediction is more uncertain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8367747-4cbe-45e1-8003-b4ba277f2741",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Your turn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f169d7-4221-4e1d-b62a-dae28963c139",
   "metadata": {},
   "source": [
    "Now it's your turn to implement a classifier! In this application, you will try to predict whether a forest fire spread and burned forest areas in the Montesinho natural park in Portugal.\n",
    "\n",
    "We are using the [Forest Fires dataset](https://www.kaggle.com/datasets/sumitm004/forest-fire-area), created by Paulo Cortez and Aníbal Morais, and available on Kaggle.\n",
    "\n",
    "Source: P. Cortez and A. Morais. A Data Mining Approach to Predict Forest Fires using Meteorological Data. In J. Neves, M. F. Santos and J. Machado Eds., New Trends in Artificial Intelligence, Proceedings of the 13th EPIA 2007 - Portuguese Conference on Artificial Intelligence, December, Guimaraes, Portugal, pp. 512-523, 2007. APPIA, ISBN-13 978-989-95618-0-9.\n",
    "\n",
    "The original dataset contains 13 columns:\n",
    "- X - x-axis spatial coordinate within the Montesinho park map: 1 to 9\n",
    "- Y - y-axis spatial coordinate within the Montesinho park map: 2 to 9\n",
    "- month - month of the year: \"jan\" to \"dec\" \n",
    "- day - day of the week: \"mon\" to \"sun\"\n",
    "- FFMC - Fine Fuel Moisture Code (FFMC) index from the [Fire Weather Index (FWI)](https://www.nwcg.gov/publications/pms437/cffdrs/fire-weather-index-system) system: 18.7 to 96.20\n",
    "- DMC - Duff Moisture Code (DMC) index from the FWI system: 1.1 to 291.3 \n",
    "- DC - Drought Code (DC) index from the FWI system: 7.9 to 860.6 \n",
    "- ISI - Initial Spread Index (ISI) index from the FWI system: 0.0 to 56.10\n",
    "- temp - temperature in Celsius degrees: 2.2 to 33.30\n",
    "- RH - relative humidity in %: 15.0 to 100\n",
    "- wind - wind speed in km/h: 0.40 to 9.40 \n",
    "- rain - outside rain in mm/m2 : 0.0 to 6.4 \n",
    "- area - the burned area of the forest (in ha): 0.00 to 1090.84\n",
    "\n",
    "In addition, we created a new column, \"class\", detailing whether the fire burned an area of forest:\n",
    "- class is equal to 0 if area = 0.00 ha\n",
    "- class is equal to 1 if area > 0.00 ha \n",
    "\n",
    "Our goal will be to predict the class using logistic regression, given the weather and FWI features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea817c8-e3db-42fd-a429-8804c19b528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "url_ff = 'https://raw.githubusercontent.com/thurmboris/Data-Science_4_Sustainability/main/data/forestfires.csv'\n",
    "forest_fire = pd.read_csv(url_ff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea0a3ee-2fda-45e2-bfbe-98f601ad0671",
   "metadata": {},
   "source": [
    "### Discover your dataset\n",
    "\n",
    "- Explore your dataset, displaying a few observations, the types of your data, some summary statistics, and the correlation matrix. Feel free to push forward your EDA using a few graphs e.g., boxplot and pairplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c1303a-7a43-4bcc-a930-b91d16acf1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c332f43-5124-4c00-ba51-061712a92bf0",
   "metadata": {},
   "source": [
    "### Two-features logistic regression\n",
    "\n",
    "We'll start with only two features, the temperature and wind.\n",
    "\n",
    "- Define your features and target variable ('class'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b933f0-96a2-451e-8909-8734cf0f2ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5283be-92e9-4556-ad86-b14901e87757",
   "metadata": {},
   "source": [
    "- Split you data intro training and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c94e19-a2b7-4f21-a43d-dc4566fa643d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd63cd9-a223-4c74-9e3a-97f0d93400a5",
   "metadata": {},
   "source": [
    "- Rescale your data, using the scaler of your choice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e86532-eb2a-4079-b1d8-fd52423e90f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac49cf1-ee80-430b-8a34-9f891e8442b7",
   "metadata": {},
   "source": [
    "- Build and train a simple logistic regression classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc882f09-0943-4969-9fc5-9d40e7e71659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0a25ac-f992-4e82-bf10-55f3f17e9f9c",
   "metadata": {},
   "source": [
    "- Compare the training and testing accuracy of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13383d7f-a616-4a72-9889-d78227f68923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96524d31-3250-4366-b2fb-cb0287dcc9fb",
   "metadata": {},
   "source": [
    "- Plot the distribution of class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bf4c7c-0a99-45cc-bb7b-5d308b4813c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ce20f6-8e83-4982-9fbd-0e658edcf8da",
   "metadata": {},
   "source": [
    "- Compute the default rate and compare it to the accuracy of your model. What do you think?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a26a920-3b24-4c99-85c3-2fa654844aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf93250-cd85-4f4e-986b-96777c2a5efe",
   "metadata": {},
   "source": [
    "- Plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e908fa50-b3ac-46f9-85c2-d57fce3e6529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbce986-6772-4ce5-9962-e4c1621f252b",
   "metadata": {},
   "source": [
    "- Plot the decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdb0adf-a2f1-40f9-8e56-2a0fd3f970f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5de1a4-32b8-48cb-a64e-6e51d7e60f37",
   "metadata": {},
   "source": [
    "### Multi-features logistic regression\n",
    "\n",
    "We will try to improve the accuracy of our previous classifier using more features, namely: 'FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind', 'rain'\n",
    "\n",
    "- Extract your new features of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0751f9a-63fc-4b04-892e-b13adada465a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0307be-edbf-414c-923a-203b848c3939",
   "metadata": {},
   "source": [
    "- Split you data intro training and test set, using 20% of observations for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4377036d-cf37-4682-b53a-724e54dce602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b4a9f8-1528-42fe-8c53-d6bdc2c36116",
   "metadata": {},
   "source": [
    "- Rescale your data, using the scaler of your choice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1f647f-9071-43b3-95a1-b8be5ae9fa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b116648-4eb6-4391-83be-192193a49f12",
   "metadata": {},
   "source": [
    "- Build and train a logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64977554-e8ac-44b0-ad5a-8b430b5844a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8b0c3e-38cc-48ae-98d8-aae95fa64263",
   "metadata": {},
   "source": [
    "- Extract the weights of your model in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdd3254-8697-4dc0-b948-7a19c5086af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aafaae9-1ecd-4a08-ae4b-d3beb05efa9b",
   "metadata": {},
   "source": [
    "- Compare the training and testing accuracy of your model. What do you think?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0395cb01-640a-4717-919d-dcdaa6952d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dad173f-42d1-44a5-95d5-1b367fb0d6b4",
   "metadata": {},
   "source": [
    "- Plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4082f4b1-7a1f-46ef-80f0-2a8d6857eb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f713bc9c-72aa-43ac-9878-ea9fe8cc1b29",
   "metadata": {},
   "source": [
    "- Compute the precision, recall, and f1 score of class 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c1666b-b78c-459c-b6c8-3c11b26a764f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4ccd5b-78bb-4f10-b4dc-0844a751b684",
   "metadata": {},
   "source": [
    "### Improve the accuracy (optional)\n",
    "\n",
    "Your goal is now to try to improve the accuracy of your model. Try to implement cross-validation techniques, different regularization and scaling, or even new features (e.g., encoding the month feature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2cdc80-47a6-4973-a074-7b2ab28aff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
