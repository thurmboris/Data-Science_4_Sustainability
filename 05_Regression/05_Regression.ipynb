{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7556b1d3-958a-416f-b059-7b1cde6e0139",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/thurmboris/Data-Science_4_Sustainability/blob/main/05_Regression/05_Regression.ipynb\" target=\"_blank\" rel=\"noopener\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dc4475-7f7d-4457-8762-bb031a0629b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Import to load arff file from url\n",
    "from scipy.io import arff\n",
    "import urllib.request\n",
    "import io \n",
    "\n",
    "# Sklearn import\n",
    "from sklearn.model_selection import train_test_split # Splitting the data set\n",
    "from sklearn.model_selection import KFold, cross_val_score # Cross validation\n",
    "from sklearn.preprocessing import MinMaxScaler # Normalization\n",
    "from sklearn.preprocessing import PolynomialFeatures # Polynomial features\n",
    "from sklearn.preprocessing import LabelEncoder #Label encoding\n",
    "from sklearn.preprocessing import OneHotEncoder # 1-hot encoding\n",
    "from sklearn.linear_model import LinearRegression # Regression linear model\n",
    "from sklearn.linear_model import Lasso # Lasso model\n",
    "from sklearn.linear_model import Ridge # Ridge model\n",
    "from sklearn.linear_model import LassoCV # Lasso with cross validation\n",
    "from sklearn.linear_model import RidgeCV # Ridge with cross validation\n",
    "from sklearn.linear_model import ElasticNet # ElasticNet model\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score # Metrics for errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a844a8c0-078c-4946-8927-e570469c601c",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9984e553-36af-42c8-9522-dd090686c913",
   "metadata": {},
   "source": [
    "<img src='https://imgs.xkcd.com/comics/linear_regression.png' width=\"400\">\n",
    "\n",
    "Source: [xqcd 1725](https://xkcd.com/1725)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4392fab0-671b-45ea-b27a-61a797c0e090",
   "metadata": {},
   "source": [
    "## Content\n",
    "\n",
    "The goal of this walkthrough is to provide you with insights on regression. After presenting the main concepts, you will be introduced to the techniques to implement these concepts in Python. Finally, it will be your turn to practice, using an application on energy efficiency. \n",
    "\n",
    "This notebook is organized as follows:\n",
    "- [Background](#Background)\n",
    "    - [Objective](#Objective)\n",
    "    - [Econometrics vs ML](#A-quick-word-on-econometrics-vs-Machine-Learning)\n",
    "    - [Model](#Model)\n",
    "        - [Least squares problem](#Least-squares-problem)\n",
    "        - [Regularization](#model-regul)\n",
    "        - [Why LASSO leads to feature selection?](#Why-LASSO-leads-to-feature-selection?)\n",
    "    - [Solving our model: learning parameters via gradient descent](#Solving-our-model:-learning-parameters-via-gradient-descent)\n",
    "- [Implementation](#Implementation)\n",
    "    - [Load and discover the dataset](#Load-and-discover-the-dataset)\n",
    "    - [Linear regression](#Linear-regression)\n",
    "        - [Splitting the dataset](#linear-split)\n",
    "        - [Create and Fit model](#linear-train)\n",
    "        - [Prediction and Evaluation](#linear-test)\n",
    "    - [Multivariate-linear regression](#Multivariate-linear-regression)\n",
    "        - [Splitting the dataset](#multivariate-split)\n",
    "        - [Encoding](#Preprocessing:-encoding-categorical-variables)\n",
    "        - [Rescaling](#rescaling)\n",
    "        - [Create and Fit model](#multivariate-train)\n",
    "        - [Prediction and Evaluation](#multivariate-test)    \n",
    "    - [Polynomial linear regression](#Polynomial-linear-regression)\n",
    "    - [Regularization](#Regularization)\n",
    "        - [Ridge](#Ridge)\n",
    "        - [Lasso](#Lasso)\n",
    "    - [K-fold cross validation](#K-fold-cross-validation)\n",
    "- [Your turn](#Your-turn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7763984b-c9d6-43b0-ba06-fd749431aa32",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "### Objective\n",
    "\n",
    "The goal of a regression is to estimate the relationships between a dependent variable (aka outcome, response, or label) and one or more independent variables (aka features, predictors, or explanatory variables).\n",
    "\n",
    "Why?\n",
    "- Predict outcome values\n",
    "- Causal inference: analyze causal relation, for instance to provide policy recommendations\n",
    "- Test a model / hypothesis\n",
    "- ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125776bc-7847-42f6-9ac5-3072241f052d",
   "metadata": {},
   "source": [
    "### A quick word on econometrics vs Machine Learning\n",
    "\n",
    "- Machine Learning and Econometrics both gather a collection of methods, including (linear) regression, that can be used to answer a research question.\n",
    "- The roots of ML is computer sciences while Econometrics is applied statistics, but...\n",
    "- ...each field shares a lot: they are built on a similar mathematical bricks such as linear algebra, optimization, statistics & probability theory\n",
    "- They (generally) differ on their goal and approach used:\n",
    "    - Econometrics is often interested in causal interpretation. To do so, you make assumptions about how your data was generated (i.e., from which distribution)\n",
    "    - The goal of ML is prediction accuracy. To do so, you train an algorithm on a subset of your data and then test this model (and train again...)\n",
    "- That being said, this is an oversimplification since there are strong overlaps between the two: e.g. ML can also be interested in causality and ML algorithms make (implicit) assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251e9265-3d22-4a07-8838-23b32fce472f",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "Suppose we have *n* observations of an outcome $\\boldsymbol{y}$ and *d* associated features $\\boldsymbol{x_1}$, $\\boldsymbol{x_2}$, ... , $\\boldsymbol{x_d}$ (note that $\\boldsymbol{y}$, $\\boldsymbol{x_1}$, ..., $\\boldsymbol{x_d}$ are vectors):\n",
    "\n",
    "| | Outcome | Feature 1 | Feature 2 | ... | Feature d |\n",
    "|:-------|:----------:|:----------:|:----------:|:----------:|:----------:|\n",
    "| Observation 1 | $y_1$ | $x_{11}$ | $x_{12}$ | ... | $x_{1d}$ |\n",
    "| Observation 2 | $y_2$ | $x_{21}$ | $x_{22}$ | ... | $x_{2d}$ |\n",
    "| ... | ... | ... | ... | ... | ... |\n",
    "| Observation n | $y_n$ | $x_{n1}$ | $x_{n2}$ | ... | $x_{nd}$ |\n",
    "\n",
    "Regression is to relate feature variables to the outcome variable, to either predict outcomes for new observations and/or to understand the effect of the features on the output. For both goals, we need to find a function that approximates the output “well enough” given some inputs.\n",
    "\n",
    "For instance, in the case of multivariate linear regression, we can write, for each observation $i$:\n",
    "$$y_i = w_0 + w_1 x_{i,1} +  w_2 x_{i,2} + ... +  w_d x_{i,d} + \\epsilon_i $$\n",
    "\n",
    "Where $\\epsilon_i$ is the error term, $w_0$ the intercept, and $w_1$, ... , $w_d$ the slope coefficients (i.e., weights) of each feature.\n",
    "\n",
    "For each observation, we call our predicted value: \n",
    "$$\\hat{y_i}:=w_0 + w_1 x_{i,1} +  w_2 x_{i,2} + ... +  w_d x_{i,d}$$\n",
    "\n",
    "In other words, we have: $y_i = \\hat{y_i} + \\epsilon_i $ \n",
    "\n",
    "More generally, let $f$ be our model function, $\\boldsymbol{w}=(w_0, w_1, ..., w_d)$ the vector of weights, and $\\boldsymbol{X}=[\\boldsymbol{x_1}$, ... , $\\boldsymbol{x_d}]$ the matrix of feature variables. For all observations, we have, with $\\boldsymbol{X_{i*}}$ the $i^{th}$ row:\n",
    "\n",
    "$$\\hat{y_i} := f(\\boldsymbol{X_{i*}}, \\boldsymbol{w})$$\n",
    "\n",
    "In our illustration, we have focused on a multivariate linear regression, but the formulation will be the same for more complex models, such as neural networks, which we will see later in this course.\n",
    "\n",
    "Now our objective is to find the predicted values $\\hat{y_i}$ that are the closest to the observations $y_i$. In other words, we want to minimize the errors $\\epsilon_i = y_i - \\hat{y_i}$. There are several possible techniques. Below, we present the simplest one, namely the *least squares* problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edb4df8-98f9-4903-ae42-65e57e0d8a84",
   "metadata": {},
   "source": [
    "#### Least squares problem\n",
    "\n",
    "The idea is to minimize the sum of squared residuals (aka RSS - Residual Sum of Squares):\n",
    "\n",
    "$$ \\min_\\boldsymbol{w} \\sum_{i=1}^n (y_i - \\hat{y_i})^2 = \\min_\\boldsymbol{w} \\sum_{i=1}^n (y_i - f(\\boldsymbol{X_{i*}}, \\boldsymbol{w}))^2 $$\n",
    "\n",
    "Graphically, for a simple linear regression, we minimize the area of the squares between our observation and our predicted value:  \n",
    "\n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/8/86/Coefficient_of_Determination.svg' width=\"600\">\n",
    "\n",
    "Source: [Wikipedia - Coefficient of determination. Author: Orzetto](https://commons.wikimedia.org/wiki/File:Coefficient_of_Determination.svg)\n",
    "\n",
    "The [coefficient of determination](https://en.wikipedia.org/wiki/Coefficient_of_determination) $R^2$ informs about the goodness of fit: $R^2= 1 -\\frac{\\color{blue}{RSS}}{\\color{red}{TSS}} $\n",
    "- Residual Sum of Squares: $\\color{blue}{RSS=\\sum_i (y_i - \\hat{y_i})^2}$\n",
    "- Total Sum of Squares: $\\color{red}{TSS=\\sum_i (y_i - \\bar{y})^2}$\n",
    "\n",
    "When $R^2=1$, then $RSS=0$, meaning all the errors are equal to zero, and the model gives \"perfect\" prediction.  \n",
    "When $R^2=0$, then $RSS=TSS$, hence our model is not more informative that taking the average of our observations.\n",
    "\n",
    "The prediction errors will generally decrease with the complexity of the model, e.g., with more features. But what could go wrong?\n",
    "- The prediction error decreases but... there is a risk of overfitting: the model cannot be generalized!\n",
    "- There may be no solutions (risk of multicollinearity of matrix $\\boldsymbol{X}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe565254-abb1-48c4-83a7-e4cfc2099707",
   "metadata": {},
   "source": [
    "<img src='https://i.postimg.cc/m2gvNQwn/model-complexity.png' width=\"600\">\n",
    "\n",
    "Source: Ann Sajee, [Model complexity accuracy and interpretability, Towards Data Science](https://towardsdatascience.com/model-complexity-accuracy-and-interpretability-59888e69ab3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5500d8-76a8-4fc0-b128-b8779ba221ab",
   "metadata": {},
   "source": [
    "#### Regularization <a id='model-regul'></a>\n",
    "\n",
    "Our objective is to tackle the limitations of the least square problem, in particular [overfitting](https://en.wikipedia.org/wiki/Overfitting). An overfitted model contains more parameters than can be justified by the data. \n",
    "\n",
    "What can we do? One technique is called [regularization](https://en.wikipedia.org/wiki/Regularization_(mathematics))\n",
    "\n",
    "The general idea is to put an additional constraint - or penalty - on our parameters $\\boldsymbol{w}$, instead of optimizing only on the errors. Here is the new problem formulation:\n",
    "\n",
    "$$ \\min_\\boldsymbol{w} L(\\boldsymbol{y}, \\boldsymbol{X}, \\boldsymbol{w}) + \\lambda R(\\boldsymbol{w}) $$\n",
    "\n",
    "- $L(\\boldsymbol{y}, \\boldsymbol{X}, \\boldsymbol{w})$ is the **loss** function. It measures the prediction error. \n",
    "    - For instance, we can use the least square loss function:\n",
    "$ L(\\boldsymbol{y}, \\boldsymbol{X}, \\boldsymbol{w}) = \\frac{1}{n} \\sum_i^n (y_i - f(\\boldsymbol{X_{i*}}, \\boldsymbol{w}))^2 $\n",
    "- $\\lambda$ is the penalty term\n",
    "- $R(\\boldsymbol{w})$ is the **regularization** function that constrains the model, typically penalizing the parameters $w_0$, $w_1$, ..., $w_d$. What regularization function should we use? Below are some common examples...\n",
    "\n",
    "**LASSO**  regression, standing for \"Least Absolute Selection and Shrinkage\", is using the 1-norm ([absolute value norm](https://en.wikipedia.org/wiki/Norm_(mathematics)#Absolute-value_norm)) of the parameters as regularization function: \n",
    "$$ R(\\boldsymbol{w})= \\sum_{j=1}^d |w_j| $$\n",
    "\n",
    "- Pros\n",
    "    - Force most entries of $\\boldsymbol{w}$ to be 0. In other words, there is selection effect, and the technique is preferred when $\\boldsymbol{w}$ is expected to be sparse\n",
    "    - It enables to do a linear regression when there are more features than observations ($d > n$)\n",
    "- Cons\n",
    "    - Arbitrary selection among highly correlated variables\n",
    "    - Selects at most $n$ features when more features than observations ($d > n$)\n",
    "    - Features with small $w_j$ values will be forced to zero\n",
    "\n",
    "**Ridge** regression is using the square of the 2-norm ([Euclidean norm](https://en.wikipedia.org/wiki/Norm_(mathematics)#Euclidean_norm)) of the parameters as regularization function: $$R(\\boldsymbol{w})= \\sum_{j=1}^d w_j^2 $$\n",
    "\n",
    "- Pros\n",
    "    - More stable solution (shrink parameters estimate). This method is thus preferred when $\\boldsymbol{w}$ is expected to take small values\n",
    "    - It enables to do a linear regression when there are more features than observations ($d > n$)\n",
    "- Cons\n",
    "    - Less sensitive to data\n",
    "    - $\\boldsymbol{w}$ is typically still not sparse\n",
    "\n",
    "**Elastic net** regression is using a linear combination of Ridge and Lasso: $$ R(\\boldsymbol{w})= \\lambda_1 \\sum_{j=1}^d |w_j| + \\lambda_2 \\sum_{j=1}^d w_j^2 $$\n",
    "\n",
    "- Pros\n",
    "    - Ridge term makes the problem convex (unique solution)\n",
    "    - Overcome some of the limitations of LASSO: can select group of highly correlated variables and more than $n$ features when more features than observations ($d > n$) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb4289a-28bd-45fc-8ac1-08ff817145e1",
   "metadata": {},
   "source": [
    "#### Why LASSO leads to feature selection?\n",
    "\n",
    "In the previous section, we have state that LASSO regression forces weights to zero, hence selecting features, while Ridge was shrinking parameters. Why is that? The answer lies in the shape of the functions. Mathematically, the ridge regularization function is convex while LASSO is not. \n",
    "\n",
    "What does it imply? Let's see graphically, in a model with two features:\n",
    "$$ y_i= w_1 x_{i,1} + w_2 x_{i,2} + \\epsilon_i $$\n",
    "\n",
    "The least square loss function is quadratic: \n",
    "$$L(w_1, w_2) = \\sum_i^n (y_i - w_1 x_{i,1} - w_2 x_{i,2})^2$$\n",
    "\n",
    "Hence, plotted in a plan, our \"indifference curves\" (i.e., the curves such that the loss function is equal to a given value) would look like elliptical contours - see figure below, in red. Without regularization, our optimum would be located at the center of the ellipse.\n",
    "\n",
    "What happens when we add a regularization term? We transform our minimization problem. Mathematically, adding the regularization term is equivalent to adding a constraint on the weights:\n",
    "- LASSO: $|w_1| + |w_2| \\leq t$\n",
    "- Ridge: $w_1^2 + w_2^2 \\leq t$\n",
    "\n",
    "Graphically, LASSO constraint looks like a diamond (cyan) while Ridge constraint is a disk (green). \n",
    "\n",
    "When we relaxed the constraints, the constrained regions (diamond and disk) get bigger, and can eventually hit the center of the ellipse. In such case, the optimum weights are the one obtained without regularization.\n",
    "\n",
    "Otherwise, the optimum weights are obtained at the intersection of the elliptical contours and of the constrained regions. With LASSO, this intersection will happen at one of the corners of the diamond, i.e., when one of the weight is equal to zero. With Ridge, the intersection will happen at one point of the circle: while the values of the weights are shrunk, they will (almost) never be exactly zero.\n",
    "\n",
    "<img src='https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jd03Hyt2bpEv1r7UijLlpg.png' width=\"600\">\n",
    "\n",
    "Source: [Ridge and Lasso Regression: L1 and L2 Regularization](https://towardsdatascience.com/ridge-and-lasso-regression-a-complete-guide-with-python-scikit-learn-e20e34bcbf0b), Saptashwa Bhattacharyya, Towards Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93156a60-d070-4bc1-a9d7-dfe574c1dacd",
   "metadata": {},
   "source": [
    "### Solving our model: learning parameters via gradient descent\n",
    "\n",
    "To find the solution of our problem, we use numerical optimization: we search the minimum by iteration. Recall the optimization problem we want to solve: minimize the prediction errors (loss function), with a constraint on our parameters (regularization function). \n",
    "\n",
    "$$ \\min_\\theta L(\\boldsymbol{y}, \\boldsymbol{X}, \\boldsymbol{w}) + \\lambda R(\\boldsymbol{w}) $$\n",
    "\n",
    "We call $J$ our objective function (also called cost function) $J:= L + \\lambda R$\n",
    "\n",
    "One possible numerical method to solve this problem is the [gradient descent](https://en.wikipedia.org/wiki/Gradient_descent). It is an optimization algorithm with iterative updating rule:\n",
    "\n",
    "0. We first start with an initial value $\\boldsymbol{w^0}=(w^0_0, w^0_1,...,w^0_d)$, selected at random or a best guess\n",
    "1. We update our parameters: $\\boldsymbol{w^{k+1}}=\\boldsymbol{w^{k}}+ \\gamma \\nabla (J[\\boldsymbol{w^{k}}])$\n",
    "    - $\\gamma$ is the learning rate\n",
    "    - $\\nabla (J[\\boldsymbol{w^{k}}])$ is the gradient, i.e., the derivatives of $J$ with respect to $w_0$, $w_1$, ..., $w_d$; and evaluated at $\\boldsymbol{w^{k}}$\n",
    "2. We continue until a given convergence criteria is obtained (fixed point)\n",
    "\n",
    "There are many other methods, but they often consist in tweaking the updating rule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6733c5-c0b8-4532-b11a-33525593d3e7",
   "metadata": {},
   "source": [
    "<img src='https://i.postimg.cc/QdkyWm9w/gradient-descent.jpg' width=\"400\">\n",
    "    \n",
    "\n",
    "Source: Saugat Bhattarai, [What is Gradient Descent in Machine Learning?](https://saugatbhattarai.com.np&#47what-is-gradient-descent-in-machine-learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce878d70-296b-4ce2-9a05-a5d0410d79e1",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "In python, a useful library exists to apply regression and other Machine Learning and statisticals tools over the data. It is the so called **sklearn**. Here is the [documentation](https://scikit-learn.org/stable/index.html). Check that you have the library installed - it is called \"scikit-learn\", else install it ([Installation guide](https://scikit-learn.org/stable/install.html)).\n",
    "\n",
    "We will use sklearn to implement various regression techniques, including the one discussed above: simple (univariate) linear regression, multivariate linear regression, polynomial linear regression, lasso, ridge, scaling, encoding, cross-validation.\n",
    "\n",
    "**Remember, you train your model (learn parameters) using your training set, and then test the\n",
    "prediction error on the test set.** \n",
    "\n",
    "Hence, after loading and cleaning our dataset, we will follow these steps:\n",
    "1. Preprocessing: split our dataset between training set (80% of observations) and test set (20% of observations), scaling, encoding\n",
    "2. Create and fit our model, i.e., learn the parameters using the training set\n",
    "3. Predict new observations and evaluate our model using the test set\n",
    "\n",
    "Ok, let's go!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408ec895-7ade-45c9-a8c2-dd284e5a9715",
   "metadata": {},
   "source": [
    "### Load and discover the dataset\n",
    "\n",
    "In this section, we will use the weather dataset, which contains weather data e.g., temperature, wind speed, humidity, rain in Canberra between November 2007 and October 2008. Let's load and explore our dataset. The file is available in the git repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c288953-a267-4f5c-9271-40079cb5fea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/thurmboris/Data-Science_4_Sustainability/main/data/weather.csv\"\n",
    "weather = pd.read_csv(url).drop_duplicates().dropna() # drop duplicates and NaN values\n",
    "\n",
    "# Display a sample of the data\n",
    "display(weather.head())\n",
    "\n",
    "#Print the data types\n",
    "print(weather.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2217a0-fa78-447c-9b7d-c893f842bdf2",
   "metadata": {},
   "source": [
    "Note that the dataset contains numerical variables (e.g., temperature, rainfall, humidity, pressure) and categorial variables (e.g., wind direction). In addition, we have weather data at 9am and 3pm. We will only work with values concerning 3pm for simplicity. Let's get some summary statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef3b2d4-ef9c-4254-a730-ebcde33acf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features of interest\n",
    "weather3pm = weather.loc[:,['Temp3pm','Humidity3pm', 'Cloud3pm', 'Pressure3pm', 'WindSpeed3pm', 'WindDir3pm', 'Sunshine', 'Rainfall']]\n",
    "\n",
    "# Summary statistics\n",
    "display(weather3pm.describe())\n",
    "\n",
    "# Correlation matrix\n",
    "display(weather3pm.corr(numeric_only = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5d4f07-25df-4901-9e7b-8da09078035c",
   "metadata": {},
   "source": [
    "### Linear regression\n",
    "\n",
    "We will first implement a simple (univariate) linear regression. Our goal in this section will be to try to predict the temperature given the level of humidity:\n",
    "\n",
    "$$Temperature_i = w_0 + w_1 Humidity_i + \\epsilon_i$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10968c4-2605-46df-a4df-66695f98639c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = weather3pm[['Humidity3pm']]\n",
    "y = weather3pm[['Temp3pm']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da1d609-f411-4205-9026-f452795d8dac",
   "metadata": {},
   "source": [
    "#### Splitting the dataset <a id='linear-split'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e022dc7-61eb-41cd-b112-8f099274231c",
   "metadata": {},
   "source": [
    "Sklearn has a very useful module to separate your dataset in a training and in a testing set called `train_test_split` ([Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)). Here is how to import it (already done at the beginning of the notebook)\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split \n",
    "```\n",
    "\n",
    "The training set will be used to retrieve the best values of the weights $w_0$ and $w_1$ according to a combination of input (humidity) and output (temperature) observations. The test set will be used to evaluate/predict our model. Since our model will be trained on particular values we want to test our data on a new set of data (the test set).\n",
    "\n",
    "The test size here is of 20% of the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7023d68-1d77-455b-a56f-06e9b1d1f83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3035add-c9a3-4b13-b98a-dad8d6981a3a",
   "metadata": {},
   "source": [
    "Notice the syntax: as arguments we provide our matrix of features (here, 'Humidity3pm' vector), our outcome vector (here, 'Temp3pm), the size of the test set (20%). We also shuffle the data before splitting to avoid potential bias, and we control how this shuffling is applied by providing a random state, in order to obtain reproducible output across multiple function calls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0a1b43-4e06-4b70-8a83-c5e58d99e2d7",
   "metadata": {},
   "source": [
    "#### Create and Fit model <a id='linear-train'></a>\n",
    "\n",
    "To predict the output variable we will use a simple linear regression, the module is called `LinearRegression` ([Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression)). Here is the import line:\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "```\n",
    "We follow three steps:\n",
    "1. Create a new `LinearRegression` model from sklearn\n",
    "2. Fill the linear model from the X_train (feature) and the y_train data (target) using the `fit()` function\n",
    "3. Check the model accuracy using the `score()` function, which returns the coefficient of determination $R^2$ of the prediction. The best possible score is 1 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a $R^2$ score of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e909b23-c4db-408d-8bd9-3267b8281632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are three steps to model something with sklearn\n",
    "# 1. Set up the model\n",
    "model = LinearRegression(fit_intercept= True)\n",
    "# 2. Use fit\n",
    "model.fit(X_train, y_train)\n",
    "# 3. Check the score/accuracy\n",
    "print(\"R\\u00b2 Score of the model: \", round(model.score(X_train, y_train), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e935629-c646-44e6-8491-ecbf664b8e75",
   "metadata": {},
   "source": [
    "After fitting the model, we can easily retrieve the values of the different weights coefficients (the intercept, and the weight of each feature):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a615f08f-a1b1-40df-b897-d2e01edc9b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Intercept: \", model.intercept_[0]) \n",
    "print(\"Features coefficients (weigths): \", model.coef_.flatten()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0847dc-82aa-4ffd-b3fb-1cc8d076c69f",
   "metadata": {},
   "source": [
    "The intercept corresponds to the value of $w_0$. There is only one coefficient,  $w_1$ linked to the humidity feature. Since we have only one value for intercept and coefficients represented as arrays, we apply `flatten()` and `[0]`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc6921d-d075-4f8c-9ef8-e7ebdb150513",
   "metadata": {},
   "source": [
    "#### Prediction and Evaluation <a id='linear-test'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ccce46-92c5-4a27-8c76-1a19582d77a9",
   "metadata": {},
   "source": [
    "Once the model is trained, we can use the `predict()` function to predict the values of the test set using `X_test`. This prediction can be compared to the truth value, i.e., `y_test`. Let's try with one value of the test set. Note that our model takes a matrix as inputs (X matrix), so even if we want to predict a scalar value we should use `[[...]]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128dbb23-825b-415d-adff-0498b84b3f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "humidity_test = X_test.iloc[0].values[0]\n",
    "temperature_predicted = model.predict([[humidity_test]]).flatten()[0]\n",
    "temperature_test = y_test.iloc[0].values[0]\n",
    "print(f\"Prediction/observed temperature for humidity {humidity_test}: {temperature_predicted:.1f}°C vs {temperature_test}°C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2af149f-9cf2-45a1-9b15-279ecf50ef0a",
   "metadata": {},
   "source": [
    "To better understand how the prediction and actual values differ, we can plot the predictions (line) and the true values from the test set (dots). It is more interesting to predict from the test set because our model is not trained on these values unlike the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d637373-0311-4c2f-a57d-447880d667b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model prediction from X_test\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7f3b64-b184-464d-9ce2-7ff5660696bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the prediction (the line) over the true value (the dots)\n",
    "plt.scatter(X_test, y_test)\n",
    "plt.plot(X_test, predictions, 'r')\n",
    "plt.title(\"Humidity level against temperature\")\n",
    "plt.xlabel('Humidity level')\n",
    "plt.ylabel('Temperature °C')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a390f16-263a-4fcc-a73d-ad784df0e15f",
   "metadata": {},
   "source": [
    "We can compare the error of our model by using some metrics like the **MAE (mean absolute error)**, **MSE (mean squared error)** or **coefficient of determination $R^2$** score. Sklearn offers some nice modules to compute these measures ([MAE](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error), [MSE](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error), [$R^2$](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score)).\n",
    "Here is the import line:\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "```\n",
    "\n",
    "These metrics takes the `y_test` values and the `predictions` as arguments. Basically it will analyse how far the prediction is from the true value. Using these metrics is very helpful when comparing the performance of model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9d60e8-8d03-422b-af93-ed637627c00c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute the MAE, the MSE and the R^2\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "print(f\"MAE: {mae:0.2f}\")\n",
    "print(f\"MSE: {mse:0.2f}\")\n",
    "print(f\"R\\u00b2: {r2:0.2f} \" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de879df-bec6-44fd-972b-a918a0edd6f2",
   "metadata": {},
   "source": [
    "It is also interesting to compare the results of these metrics between the data from the *test set* and those from the *train set* to see whether our model generalizes well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9a003d-89f5-43d9-ae48-b3a5a49e0683",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = model.predict(X_train)\n",
    "mae_train = mean_absolute_error(y_train, predictions_train)\n",
    "mse_train = mean_squared_error(y_train, predictions_train)\n",
    "r2_train = r2_score(y_train, predictions_train)\n",
    "\n",
    "print(f\"MAE test set: {mae:0.2f}; MAE train set: {mae_train:0.2f};\")\n",
    "print(f\"MSE test set: {mse:0.2f}; MSE train set: {mse_train:0.2f};\")\n",
    "print(f\"R\\u00b2 test set: {r2:0.2f}; R\\u00b2 train set: {r2_train:0.2f};\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129db0b0-bb62-49f7-abbc-fb7c784c35b7",
   "metadata": {},
   "source": [
    "Remember, the higher the $R^2$ value, the better the fit. In this case, the testing data yields a higher coefficient as well as lower mean absolute and mean squared errors. While it might seem a bit counterintuitive, one possible explanation lies in the observations selected when we split our dataset into training/test set. One remedy would be to rely on cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b24342-de96-4c76-bffb-7ee7be91495f",
   "metadata": {},
   "source": [
    "### Multivariate linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473bce73-3a6d-446f-a951-17de9e8d5c67",
   "metadata": {},
   "source": [
    "We will now apply the same method to several features, namely, humidity, pressure, wind speed, wind direction, sunshine, rainfall, and cloud data to predict the temperature, still at 3pm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816effc4-c997-441d-8234-59408fe79fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = weather[['Humidity3pm', 'Cloud3pm', 'Pressure3pm', 'WindSpeed3pm', 'WindDir3pm', 'Sunshine', 'Rainfall']] \n",
    "y = weather[['Temp3pm']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ab2d22-ae5a-48c7-96fd-1c5ee2182f1e",
   "metadata": {},
   "source": [
    "#### Splitting dataset <a id='multivariate-split'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9757fd7-ad04-4812-a2b5-bacc06d19bd5",
   "metadata": {},
   "source": [
    "We apply the same procedure as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff29ea2d-ef2e-4065-9d71-d36db8ae966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b946fce-a5c5-483b-babe-5cbd2c27be3b",
   "metadata": {},
   "source": [
    "#### Preprocessing: encoding categorical variables\n",
    "\n",
    "The feature 'WindDir3pm' is a categorical variable. To use it in our model, we need to encode it. Here, we will use a label encoding, using the sklearn module `LabelEncoder`. As an alternative, we could use 1-hot encoding, with the sklearn module `OneHotEncoder`. Here are the import lines:\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "```\n",
    "\n",
    "**Note:** You should encore your data after splitting the dataset to avoid data leakage (train-test contamination), first transforming the training set and then the test set based on the encoding maps from train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9483ee-4279-4d8e-81fd-8b24cb418174",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(X_train[['WindDir3pm']])\n",
    "# Extract the column of interest\n",
    "wind_dir_3pm = X_train[['WindDir3pm']].values.ravel()\n",
    "wind_dir_3pm_test = X_test[['WindDir3pm']].values.ravel()\n",
    "#Define the encoder\n",
    "le = LabelEncoder()\n",
    "#Fit the encoder\n",
    "le.fit(wind_dir_3pm)\n",
    "#Transform the train and the test set\n",
    "X_train = X_train.assign(WindDir3pm=le.transform(wind_dir_3pm))\n",
    "X_test = X_test.assign(WindDir3pm=le.transform(wind_dir_3pm_test))\n",
    "print(X_train[['WindDir3pm']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ffb331-7ce5-48ba-8e5a-c24d6bac380b",
   "metadata": {},
   "source": [
    "#### Rescaling\n",
    "\n",
    "Next, we rescale our data.\n",
    "\n",
    "**Note:** Generally you should normalize the data right after splitting the dataset. The normalization is important here to reduce the variance of our model and get better results.\n",
    "\n",
    "We can use the sklearn `MinMaxScaler` module to normalize the data. This estimator scales and translates each feature individually such that it is in the given range on the training set, e.g. between zero and one. Here is the import line:\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae1dd0d-936d-4e7c-a3c5-2463fde05582",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the scaler\n",
    "scaler = MinMaxScaler()\n",
    "#Fit the scaler\n",
    "scaler.fit(X_train)\n",
    "#Transform the train and the test set\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "## Note that these two steps can be merged into one (only for the train set)\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661fd9a2-9b49-409d-883a-4f8a67d9bcc6",
   "metadata": {},
   "source": [
    "#### Create and Fit model <a id='multivariate-train'></a>\n",
    "\n",
    "We follow the same steps as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4701ab3-91c8-4219-bd3e-4dbf2dabe463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Set up the model\n",
    "model = LinearRegression()\n",
    "# 2. Use fit\n",
    "model.fit(X_train, y_train)\n",
    "# 3. Check the score/accuracy\n",
    "print(\"R\\u00b2 Score of the model: \", round(model.score(X_train, y_train), 3))\n",
    "# 4. Print the coefficients of the linear model\n",
    "print(\"Intercept: \", model.intercept_[0]) \n",
    "model_coeff = pd.DataFrame(model.coef_.flatten(), \n",
    "                     index=['Humidity3pm', 'Cloud3pm', 'Pressure3pm', 'WindSpeed3pm', 'WindDir3pm', 'Sunshine', 'Rainfall'],\n",
    "                     columns=['Coefficients multivariate model'])\n",
    "model_coeff # Get the coefficients, w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4f3195-df05-4e44-bcf5-a48798290afc",
   "metadata": {},
   "source": [
    "The coefficient values inform us about the relative importance of each feature for our prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f84a99e-91e9-404f-9530-e2815863c9a1",
   "metadata": {},
   "source": [
    "#### Prediction and evaluation <a id='multivariate-test'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca48e7b-b5e6-41b9-994e-fc7473178231",
   "metadata": {},
   "source": [
    "Finally, we evaluate our model performance following the same procedure as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b808dfe-3938-4776-b3f0-ba1158639bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict:\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Compute the MAE, the MSE and the R^2 on the test set\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "# Compute the MAE, the MSE and the R^2 on the training set\n",
    "predictions_train = model.predict(X_train)\n",
    "mae_train = mean_absolute_error(y_train, predictions_train)\n",
    "mse_train = mean_squared_error(y_train, predictions_train)\n",
    "r2_train = r2_score(y_train, predictions_train)\n",
    "\n",
    "print(f\"MAE test set: {mae:0.2f}; MAE training set: {mae_train:0.2f};\")\n",
    "print(f\"MSE test set: {mse:0.2f}; MSE training set: {mse_train:0.2f};\")\n",
    "print(f\"R\\u00b2 test set: {r2:0.2f}; R\\u00b2 training set: {r2_train:0.2f};\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae2b3d5-e92a-4f9b-858e-3b445b42da0c",
   "metadata": {},
   "source": [
    "The mean absolute error and mean squared error in our multivariate analysis are lower than in the univariate case: as expected, adding more complexity (features) seemed to have improved our prediction.\n",
    "\n",
    "Note that you should not use the $R^2$ to compare several models since the indicator is sensitive to the number of features. Instead, you can for instance use the [Adjusted $R^2$](https://en.wikipedia.org/wiki/Coefficient_of_determination#Adjusted_R2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507f9093-8d25-4100-aefd-028a591d7892",
   "metadata": {},
   "source": [
    "### Polynomial linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b860983d-4ab8-4539-987e-7389c2ee1fdd",
   "metadata": {},
   "source": [
    "Using polynomial regression enables you to predict the best fit line that follows the pattern (curve) of the data. It tends to increase the performance of the model. We are using the module  `PolynomialFeatures` to preprocess our data ([Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)):\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "```\n",
    "\n",
    "The function `PolynomialFeatures` generates a new feature matrix consisting of all polynomial combinations of the features with degree less than or equal to the specified degree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57bad78-09db-4851-bca7-aed019401b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use a degree 2\n",
    "poly = PolynomialFeatures(2)\n",
    "# Transform our training and test set\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "# Feature name:\n",
    "X_poly_features = poly.get_feature_names_out(['Humidity3pm', 'Cloud3pm', 'Pressure3pm', 'WindSpeed3pm', 'WindDir3pm', 'Sunshine', 'Rainfall'])\n",
    "print(X_poly_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9ff39b-d50d-4352-bf2e-eeebcb849cd8",
   "metadata": {},
   "source": [
    "Now we proceed as before, performing a linear regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7620c4-27ef-46d0-b3fc-a43d3683c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the model\n",
    "model_poly = LinearRegression(fit_intercept=False) # we don't need fit intercept since polynomial features function add a column of ones to the data \n",
    "\n",
    "# Fit\n",
    "model_poly.fit(X_train_poly, y_train)\n",
    "\n",
    "# Check the score/accuracy\n",
    "print(\"R\\u00b2 Score of the model: \", round(model_poly.score(X_train_poly, y_train), 3))\n",
    "\n",
    "# Print the coefficients of the linear model\n",
    "model_coeff = pd.DataFrame(model_poly.coef_.flatten(), \n",
    "                     index=X_poly_features,\n",
    "                     columns=['Coefficients polynomial model'])\n",
    "model_coeff # Get the coefficients, w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aa43f9-24d2-4240-a70c-56dd980360e0",
   "metadata": {},
   "source": [
    "Finally, we evaluate the performance of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed5f470-252b-4dbd-8923-b3f385ce2014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict:\n",
    "predictions = model_poly.predict(X_test_poly)\n",
    "\n",
    "# Compute the MAE, the MSE and the R^2 on the test set\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "# Compute the MAE, the MSE and the R^2 on the training set\n",
    "predictions_train = model_poly.predict(X_train_poly)\n",
    "mae_train = mean_absolute_error(y_train, predictions_train)\n",
    "mse_train = mean_squared_error(y_train, predictions_train)\n",
    "r2_train = r2_score(y_train, predictions_train)\n",
    "\n",
    "print(f\"MAE test set: {mae:0.2f}; MAE training set: {mae_train:0.2f};\")\n",
    "print(f\"MSE test set: {mse:0.2f}; MSE training set: {mse_train:0.2f};\")\n",
    "print(f\"R\\u00b2 test set: {r2:0.2f}; R\\u00b2 training set: {r2_train:0.2f};\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8eef147-4cf8-409b-87b4-ce94ff5b32a3",
   "metadata": {},
   "source": [
    "The mean absolute and mean square errors on the test set decreased. \n",
    "\n",
    "However, beware, adding too many features may cause overfitting. Remember that overfitting is is the tendency of data mining procedures to tailor models to the training data, at the expense of generalization to previously unseen data points. \n",
    "\n",
    "For instance, if we were to use polynomial features with a degree 3, the mean absolute and mean square errors on the training set would decrease, but the errors on the test set would dramatically increase - and the $R^2$ on the test set would even be negative. Try it!\n",
    "\n",
    "To avoid such issue, we can implement some regularization techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b479c69-6f18-47c0-b5e0-d21faf02f5f7",
   "metadata": {},
   "source": [
    "### Regularization <a id='implement-regul'></a>\n",
    "\n",
    "We will now implement some regularization techniques discussed above, in combination of our previous polynomial linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37aa6718-2463-4e2c-bc2a-e644fd158012",
   "metadata": {},
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d8e0cf-3bfa-4cc6-bbff-988e3da32a1c",
   "metadata": {},
   "source": [
    "We can use the sklearn `Lasso` module to implement a Lasso regularization ([Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)). Here is the import line:\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import Lasso\n",
    "```\n",
    "\n",
    "The procedure is the same as before. Since we already split our dataset and preprocessed our training and test sets, we can create the model, fit it, and then evaluate its performance.\n",
    "\n",
    "When creating the model, we can specify the penalty term, `alpha` as an argument of `Lasso()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d447bb-2150-4566-80c6-64c4088d1316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the model\n",
    "lasso_model = Lasso(alpha=0.2, fit_intercept=False)\n",
    "\n",
    "# Use fit\n",
    "lasso_model.fit(X_train_poly, y_train)\n",
    "\n",
    "# Check the score/accuracy\n",
    "print(\"R\\u00b2 Score of the model: \", round(lasso_model.score(X_train_poly, y_train), 3))\n",
    "\n",
    "# Print the coefficients of the linear model\n",
    "model_coeff = pd.DataFrame(lasso_model.coef_.flatten(), \n",
    "                     index=X_poly_features,\n",
    "                     columns=['Coefficients Lasso model'])\n",
    "model_coeff "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09736396-e3d2-4189-a95d-a33887c61561",
   "metadata": {},
   "source": [
    "Notice the weights? Most of them were forced to zero, meaning our model will not use the corresponding features for its prediction. The intuition here is that the corresponding features hadn’t provided enough predictive power to be worth considering alongside the other features.\n",
    "\n",
    "Let's keep going with the evaluation of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b295bbe-1f23-4e72-9366-d11da3c02983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict:\n",
    "predictions = lasso_model.predict(X_test_poly)\n",
    "\n",
    "# Compute the MAE, the MSE and the R^2 on the test set\n",
    "mae_lasso = mean_absolute_error(y_test, predictions)\n",
    "mse_lasso = mean_squared_error(y_test, predictions)\n",
    "r2_lasso = r2_score(y_test, predictions)\n",
    "\n",
    "# Compute the MAE, the MSE and the R^2 on the training set\n",
    "predictions_train = lasso_model.predict(X_train_poly)\n",
    "mae_train_lasso = mean_absolute_error(y_train, predictions_train)\n",
    "mse_train_lasso = mean_squared_error(y_train, predictions_train)\n",
    "r2_train_lasso = r2_score(y_train, predictions_train)\n",
    "\n",
    "print(f\"MAE test set: {mae_lasso:0.2f}; MAE training set: {mae_train_lasso:0.2f};\")\n",
    "print(f\"MSE test set: {mse_lasso:0.2f}; MSE training set: {mse_train_lasso:0.2f};\")\n",
    "print(f\"R\\u00b2 test set: {r2_lasso:0.2f}; R\\u00b2 training set: {r2_train_lasso:0.2f};\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5aa6c3-d8a1-4b41-aff2-a526d4af5442",
   "metadata": {},
   "source": [
    "As a result of Lasso regularization, the MAE and MSE on the test set are increasing. Let's pursue our exploration with a Ridge regularization:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a84e5c3-1b82-4d58-8e2b-156eded59ab5",
   "metadata": {},
   "source": [
    "#### Ridge\n",
    "\n",
    "We can use the sklearn `Ridge` module to implement a Ridge regularization ([Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)). Here is the import line:\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import Ridge\n",
    "```\n",
    "\n",
    "We proceed as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5035aba2-dddc-442d-9022-4c891ab71ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the model\n",
    "ridge_model = Ridge(alpha=1.0, fit_intercept=False)\n",
    "\n",
    "# Use fit\n",
    "ridge_model.fit(X_train_poly, y_train)\n",
    "\n",
    "# Check the score/accuracy\n",
    "print(\"R\\u00b2 Score of the model: \", round(ridge_model.score(X_train_poly, y_train), 3))\n",
    "\n",
    "# Print the coefficients of the linear model\n",
    "model_coeff = pd.DataFrame(ridge_model.coef_.flatten(),\n",
    "                     index=X_poly_features,\n",
    "                     columns=['Coefficients Ridge model'])\n",
    "model_coeff['Coefficients Lasso model']=lasso_model.coef_.flatten()\n",
    "model_coeff['Coefficients polynomial model']=model_poly.coef_.flatten()\n",
    "model_coeff "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c80654-6691-489d-8ad2-c953a82b259d",
   "metadata": {},
   "source": [
    "Note how the coefficients with the Ridge regularization were shrinked, but not forced to zero as in the Lasso regularization. \n",
    "\n",
    "Let's evaluate our new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf0ae93-d287-4fe8-b8c1-726906cb2478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict:\n",
    "predictions = ridge_model.predict(X_test_poly)\n",
    "\n",
    "# Compute the MAE, the MSE and the R^2 on the test set\n",
    "mae_ridge = mean_absolute_error(y_test, predictions)\n",
    "mse_ridge = mean_squared_error(y_test, predictions)\n",
    "r2_ridge = r2_score(y_test, predictions)\n",
    "\n",
    "# Compute the MAE, the MSE and the R^2 on the training set\n",
    "predictions_train = ridge_model.predict(X_train_poly)\n",
    "mae_train_ridge = mean_absolute_error(y_train, predictions_train)\n",
    "mse_train_ridge = mean_squared_error(y_train, predictions_train)\n",
    "r2_train_ridge = r2_score(y_train, predictions_train)\n",
    "\n",
    "print(f\"MAE test set: {mae_ridge:0.2f}; MAE training set: {mae_train_ridge:0.2f};\")\n",
    "print(f\"MSE test set: {mse_ridge:0.2f}; MSE training set: {mse_train_ridge:0.2f};\")\n",
    "print(f\"R\\u00b2 test set: {r2_ridge:0.2f}; R\\u00b2 training set: {r2_train_ridge:0.2f};\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1360b2cf-eef3-4181-89b4-cea2eacf331a",
   "metadata": {},
   "source": [
    "Let's visualize the MAE and MSE on the test data obtained in our different models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655d50d2-160d-4817-a61b-683685573552",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison = pd.DataFrame([mae, mse], index=['MAE', 'MSE'], columns=['Polynomial model'])\n",
    "model_comparison['LASSO']=[mae_lasso, mse_lasso]\n",
    "model_comparison['Ridge']=[mae_ridge, mse_ridge]\n",
    "model_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ec3f28-58c3-4864-87aa-ea7061124289",
   "metadata": {},
   "source": [
    "The polynomial and Ridge models seem to perform similarly. \n",
    "\n",
    "However, note that the regularization parameter $\\alpha$ has a large impact on MAE and MSE in the test data. Moreover, the relationship between the test data MSE and $\\alpha$ is complicated and non-monotonic. Hence, one popular method for choosing the regularization parameter is cross-validation, which we will implement below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30e8907-031c-442e-b3ab-30dd7bda0fa0",
   "metadata": {},
   "source": [
    "### K-fold cross validation\n",
    "\n",
    "Roughly speaking, cross-validation splits the training dataset into many training/testing subsets, then chooses the regularization parameter value that minimizes the average MSE.\n",
    "\n",
    "More precisely, k-fold cross-validation does the following:\n",
    "\n",
    "1. Partition the dataset randomly into k subsets/”folds”.  \n",
    "2. Compute $MSE_j(\\alpha)=$ mean squared error in j-th subset when using the j-th subset as test data, and other k-1 as training data.  \n",
    "3. Minimize average (across folds) MSE $\\min_\\alpha \\frac{1}{k}\\sum_{j=1}^k MSE_j(\\alpha)$. \n",
    "\n",
    "<img src='https://scikit-learn.org/stable/_images/grid_search_cross_validation.png' width=\"500\">\n",
    "\n",
    "You can find a more detailed description of cross-validation [here](https://scikit-learn.org/stable/modules/cross_validation.html).\n",
    "\n",
    "We will implement cross validation in addition of our previous polynomial linear regression with ridge regularization. We are using the sklearn `RidgeCV` module ([Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html)). Here is the import line:\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import RidgeCV\n",
    "```\n",
    "\n",
    "In case, a similar module exists for Lasso regularization with cross-validation, namely `LassoCV` ([Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html)).\n",
    "\n",
    "With the argument `cv`, we can specify the number of folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13478841-33dc-4f1f-96d4-dc47a1b858af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the model\n",
    "ridge_cv_model = RidgeCV(cv=5, fit_intercept=False)\n",
    "\n",
    "# Use fit\n",
    "ridge_cv_model.fit(X_train_poly, y_train)\n",
    "\n",
    "# Check the score/accuracy\n",
    "print(\"R\\u00b2 Score of the model: \", round(ridge_cv_model.score(X_train_poly, y_train), 3))\n",
    "\n",
    "# Print the coefficients of the linear model\n",
    "model_coeff['Coefficients Ridge-CV model']=ridge_cv_model.coef_.flatten()\n",
    "model_coeff "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8d4b7b-c366-4d40-85f9-d7d0a8115045",
   "metadata": {},
   "source": [
    "As always, let's evaluate our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d775d4-bee0-4b00-8c3a-649bfddeb877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict:\n",
    "predictions = ridge_cv_model.predict(X_test_poly)\n",
    "\n",
    "# Compute the MAE, the MSE and the R^2 on the test set\n",
    "mae_ridge_cv = mean_absolute_error(y_test, predictions)\n",
    "mse_ridge_cv = mean_squared_error(y_test, predictions)\n",
    "r2_ridge_cv = r2_score(y_test, predictions)\n",
    "\n",
    "# Compute the MAE, the MSE and the R^2 on the training set\n",
    "predictions_train = ridge_cv_model.predict(X_train_poly)\n",
    "mae_train_ridge_cv = mean_absolute_error(y_train, predictions_train)\n",
    "mse_train_ridge_cv = mean_squared_error(y_train, predictions_train)\n",
    "r2_train_ridge_cv = r2_score(y_train, predictions_train)\n",
    "\n",
    "print(f\"MAE test set: {mae_ridge:0.2f}; MAE training set: {mae_train_ridge:0.2f};\")\n",
    "print(f\"MSE test set: {mse_ridge:0.2f}; MSE training set: {mse_train_ridge:0.2f};\")\n",
    "print(f\"R\\u00b2 test set: {r2_ridge:0.2f}; R\\u00b2 training set: {r2_train_ridge:0.2f};\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028b7425-49bd-41d8-88f5-5d2f4bcf364e",
   "metadata": {},
   "source": [
    "Let's compare our model to the previous ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79656074-a0e1-4a87-8f73-28bfa57a57d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison['Ridge with Cross Validation']=[mae_ridge_cv, mse_ridge_cv]\n",
    "model_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a70331-8134-4189-85f9-880ef1bb1401",
   "metadata": {},
   "source": [
    "By optimizing the regularization parameter, the MAE and MSE decreased a little."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8367747-4cbe-45e1-8003-b4ba277f2741",
   "metadata": {},
   "source": [
    "## Your turn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f169d7-4221-4e1d-b62a-dae28963c139",
   "metadata": {},
   "source": [
    "Now it's your turn to play with ML algorithms! In this application, you will study the energy efficiency of buildings. More precisely, you will try to predict the heating loads of buildings based on the following features:\n",
    "- X1 Relative Compactness\n",
    "- X2 Surface Area\n",
    "- X3 Wall Area\n",
    "- X4 Roof Area\n",
    "- X5 Overall Height\n",
    "- X6 Orientation\n",
    "- X7 Glazing Area\n",
    "- X8 Glazing Area Distribution\n",
    "\n",
    "You will use the [Energy-Efficiency-Dataset](https://www.openml.org/search?type=data&status=active&id=43338), created by Angeliki Xifara, processed by Athanasios Tsanas, and made available on [OpenML](https://www.openml.org/), an open platform for sharing datasets, algorithms, and experiments.\n",
    "\n",
    "The format of the dataset is called \"arff\" (Attribute Relation File Format). You can open these files using the [Scipy](https://scipy.org/) library. To open such file from an URL, you will also need to import `urllib.request` and `io`. If everything is installed, you can run the following lines of code to obtain a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea817c8-e3db-42fd-a429-8804c19b528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/thurmboris/Data-Science_4_Sustainability/main/data/energy-efficiency.arff'\n",
    "ftpstream = urllib.request.urlopen(url)\n",
    "data = arff.loadarff(io.StringIO(ftpstream.read().decode('utf-8')))\n",
    "df = pd.DataFrame(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea0a3ee-2fda-45e2-bfbe-98f601ad0671",
   "metadata": {},
   "source": [
    "**Discover your dataset**\n",
    "\n",
    "- Explore your dataset, displaying a few observations, the types of your data, some summary statistics, the correlation matrix. Feel free to push forward your EDA, for instance using some graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c1303a-7a43-4bcc-a930-b91d16acf1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4573a522-f6a6-4dd6-a68d-fbbfb8bdae99",
   "metadata": {},
   "source": [
    "**Multivariate linear regression**\n",
    "\n",
    "You will first implement a multivariate linear regression, using all the features X to predict the heating load Y1.\n",
    "\n",
    "- Select your features and split your dataset between training and test set, using a 80-20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9e8542-7945-41b8-afe4-41167f95cbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bb7b7c-4356-40a0-b1fc-8ce4f2461270",
   "metadata": {},
   "source": [
    "- Rescale your features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cbdf15-b4c3-44e7-a806-c7f5782c1914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f3de85-1699-43db-9560-c8cf51c376ad",
   "metadata": {},
   "source": [
    "- Create a linear regression model and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6346ee56-49f9-41fc-b650-29e3b0c4323d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e68141e-abc3-45be-bd5e-0181be3c9650",
   "metadata": {},
   "source": [
    "- What is the $R^2$ of your model?\n",
    "- Display a dataframe with the coefficients of your model. Which ones are relatively more important? Can you interpret this result using your intuition?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac297b2-c550-4398-a9a3-0dc6d66d7700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06058101-939a-4f42-8f70-4dec794411f4",
   "metadata": {},
   "source": [
    "- What are the MAE, MSE, and $R^2$ on the test data? How do they compare to the same metrics on the training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0901dd21-e239-4c3d-a7d1-3a28e70d1171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbbd52e-40d0-4eb0-88df-3ed3aa47d705",
   "metadata": {},
   "source": [
    "**Polynomial linear regression**\n",
    "\n",
    "- Generate a new feature matrix consisting of all polynomial combinations of the features with degree less than or equal to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5803838-1e0e-4738-8ecf-a50eabcf7030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b68850-7df7-496f-b93d-f0f14384eab3",
   "metadata": {},
   "source": [
    "- Train a linear regression model with polynomial features\n",
    "- What is the $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0172c7d8-4f78-4117-8df0-f54a4d1769f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a31c9b3-8f4f-42c4-b7bc-7f863e0223af",
   "metadata": {},
   "source": [
    "- What are the MAE, MSE, and $R^2$ on the test data? How do they compare to the same metrics on the training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deb303c-4448-4459-8492-4baff05b398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cf576e-f6ee-439a-a52c-a9c53b14fdf3",
   "metadata": {},
   "source": [
    "**Regularization**\n",
    "\n",
    "- Train a linear regression model with polynomial features and ridge regression\n",
    "- What are the MAE, MSE, and $R^2$ on the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbfb723-c9da-4bb7-a13d-b24ab0b8f871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f95383d-b3de-419c-a25a-36b0e8c97ecf",
   "metadata": {},
   "source": [
    "- Train a linear regression model with polynomial features and lasso regression\n",
    "- What are the MAE, MSE, and $R^2$ on the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524ba723-f7b7-464e-8dd1-74443c5b252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6684f684-68dc-4dc6-b350-1167637e3434",
   "metadata": {},
   "source": [
    "**Cross-validation**\n",
    "\n",
    "- Train a linear regression model with polynomial features, cross-validation, and the regularization technique of your choice (you can even explore other ones, such as Elastic Net)\n",
    "- What are the MAE, MSE, and $R^2$ on the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbbc6ab-239c-4a8b-8ff6-62baa5dccad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87a4c2b-4d4e-43c0-b8d3-0a1507c5f72b",
   "metadata": {},
   "source": [
    "**Model comparison**\n",
    "\n",
    "- Compare your models. Which one gives the most accurate prediction?\n",
    "- Display the coefficients of your best model. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c20480-a91a-4141-8c70-2959d3ef4027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af759c9e-b26a-4105-9cb5-1a768d7603ae",
   "metadata": {},
   "source": [
    "Feel free to try to improve the prediction of your model implementing other algorithms, preprocessing techniques, and playing with the parameters of your model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60fd70d-3849-4981-83b4-d42219a97673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
